{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "junior-packaging",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#General\" data-toc-modified-id=\"General-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>General</a></span><ul class=\"toc-item\"><li><span><a href=\"#Definitions\" data-toc-modified-id=\"Definitions-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Definitions</a></span></li><li><span><a href=\"#Notation\" data-toc-modified-id=\"Notation-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Notation</a></span></li><li><span><a href=\"#Splitting-the-Data-Set\" data-toc-modified-id=\"Splitting-the-Data-Set-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Splitting the Data Set</a></span><ul class=\"toc-item\"><li><span><a href=\"#K-fold-Cross-Validation\" data-toc-modified-id=\"K-fold-Cross-Validation-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>K-fold Cross Validation</a></span></li></ul></li><li><span><a href=\"#Errors\" data-toc-modified-id=\"Errors-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Errors</a></span></li><li><span><a href=\"#Outlier-Detection\" data-toc-modified-id=\"Outlier-Detection-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Outlier Detection</a></span></li><li><span><a href=\"#Optimization\" data-toc-modified-id=\"Optimization-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Optimization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convexity\" data-toc-modified-id=\"Convexity-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Convexity</a></span></li></ul></li><li><span><a href=\"#Feature-Selection\" data-toc-modified-id=\"Feature-Selection-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Feature Selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Typical-methods\" data-toc-modified-id=\"Typical-methods-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>Typical methods</a></span></li></ul></li><li><span><a href=\"#Standardization\" data-toc-modified-id=\"Standardization-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Standardization</a></span></li><li><span><a href=\"#Hyperparameter-Optimization\" data-toc-modified-id=\"Hyperparameter-Optimization-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Hyperparameter Optimization</a></span></li></ul></li><li><span><a href=\"#Supervised-Learning\" data-toc-modified-id=\"Supervised-Learning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Supervised Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#KNN\" data-toc-modified-id=\"KNN-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>KNN</a></span></li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Naive Bayes</a></span></li><li><span><a href=\"#Ensemble-Methods\" data-toc-modified-id=\"Ensemble-Methods-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Ensemble Methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Averaging\" data-toc-modified-id=\"Averaging-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Averaging</a></span></li><li><span><a href=\"#Stacking\" data-toc-modified-id=\"Stacking-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Stacking</a></span></li><li><span><a href=\"#Random-Forests\" data-toc-modified-id=\"Random-Forests-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Random Forests</a></span></li></ul></li><li><span><a href=\"#Regression\" data-toc-modified-id=\"Regression-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Change-of-basis\" data-toc-modified-id=\"Change-of-basis-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Change of basis</a></span><ul class=\"toc-item\"><li><span><a href=\"#y-intercept\" data-toc-modified-id=\"y-intercept-2.5.1.1\"><span class=\"toc-item-num\">2.5.1.1&nbsp;&nbsp;</span>y-intercept</a></span></li><li><span><a href=\"#Degree-p-polynomial\" data-toc-modified-id=\"Degree-p-polynomial-2.5.1.2\"><span class=\"toc-item-num\">2.5.1.2&nbsp;&nbsp;</span>Degree p polynomial</a></span></li><li><span><a href=\"#Periodic-bases\" data-toc-modified-id=\"Periodic-bases-2.5.1.3\"><span class=\"toc-item-num\">2.5.1.3&nbsp;&nbsp;</span>Periodic bases</a></span></li><li><span><a href=\"#Gaussian-radial-basis-function-(RBF)\" data-toc-modified-id=\"Gaussian-radial-basis-function-(RBF)-2.5.1.4\"><span class=\"toc-item-num\">2.5.1.4&nbsp;&nbsp;</span>Gaussian radial basis function (RBF)</a></span></li></ul></li><li><span><a href=\"#Kernels\" data-toc-modified-id=\"Kernels-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Kernels</a></span></li><li><span><a href=\"#Loss-Functions\" data-toc-modified-id=\"Loss-Functions-2.5.3\"><span class=\"toc-item-num\">2.5.3&nbsp;&nbsp;</span>Loss Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#L2-Loss-Function-(least-squares)\" data-toc-modified-id=\"L2-Loss-Function-(least-squares)-2.5.3.1\"><span class=\"toc-item-num\">2.5.3.1&nbsp;&nbsp;</span>L2 Loss Function (least squares)</a></span></li><li><span><a href=\"#L1-Loss-Function-(robust-regression)\" data-toc-modified-id=\"L1-Loss-Function-(robust-regression)-2.5.3.2\"><span class=\"toc-item-num\">2.5.3.2&nbsp;&nbsp;</span>L1 Loss Function (robust regression)</a></span></li><li><span><a href=\"#L$\\infty$-Loss-Function-(another-robust-regression)\" data-toc-modified-id=\"L$\\infty$-Loss-Function-(another-robust-regression)-2.5.3.3\"><span class=\"toc-item-num\">2.5.3.3&nbsp;&nbsp;</span>L$\\infty$ Loss Function (another robust regression)</a></span></li></ul></li><li><span><a href=\"#MLE-and-MAP\" data-toc-modified-id=\"MLE-and-MAP-2.5.4\"><span class=\"toc-item-num\">2.5.4&nbsp;&nbsp;</span>MLE and MAP</a></span></li><li><span><a href=\"#Optimization-Method:-Finding-Loss-Function-Minimizer-(regression-weights)\" data-toc-modified-id=\"Optimization-Method:-Finding-Loss-Function-Minimizer-(regression-weights)-2.5.5\"><span class=\"toc-item-num\">2.5.5&nbsp;&nbsp;</span>Optimization Method: Finding Loss Function Minimizer (regression weights)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normal-Equations\" data-toc-modified-id=\"Normal-Equations-2.5.5.1\"><span class=\"toc-item-num\">2.5.5.1&nbsp;&nbsp;</span>Normal Equations</a></span></li><li><span><a href=\"#Gradient-Descent\" data-toc-modified-id=\"Gradient-Descent-2.5.5.2\"><span class=\"toc-item-num\">2.5.5.2&nbsp;&nbsp;</span>Gradient Descent</a></span></li><li><span><a href=\"#Stochastic-Gradient-Descent\" data-toc-modified-id=\"Stochastic-Gradient-Descent-2.5.5.3\"><span class=\"toc-item-num\">2.5.5.3&nbsp;&nbsp;</span>Stochastic Gradient Descent</a></span></li></ul></li><li><span><a href=\"#Regularization\" data-toc-modified-id=\"Regularization-2.5.6\"><span class=\"toc-item-num\">2.5.6&nbsp;&nbsp;</span>Regularization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Types\" data-toc-modified-id=\"Types-2.5.6.1\"><span class=\"toc-item-num\">2.5.6.1&nbsp;&nbsp;</span>Types</a></span></li><li><span><a href=\"#Typical-loss-functions-and-regularizations\" data-toc-modified-id=\"Typical-loss-functions-and-regularizations-2.5.6.2\"><span class=\"toc-item-num\">2.5.6.2&nbsp;&nbsp;</span>Typical loss functions and regularizations</a></span></li></ul></li></ul></li><li><span><a href=\"#Linear-Classifiers\" data-toc-modified-id=\"Linear-Classifiers-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Linear Classifiers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression:\" data-toc-modified-id=\"Logistic-Regression:-2.6.1\"><span class=\"toc-item-num\">2.6.1&nbsp;&nbsp;</span>Logistic Regression:</a></span></li><li><span><a href=\"#Support-Vector-Machine-(SVM):\" data-toc-modified-id=\"Support-Vector-Machine-(SVM):-2.6.2\"><span class=\"toc-item-num\">2.6.2&nbsp;&nbsp;</span>Support Vector Machine (SVM):</a></span></li><li><span><a href=\"#Muti-class-classifiers\" data-toc-modified-id=\"Muti-class-classifiers-2.6.3\"><span class=\"toc-item-num\">2.6.3&nbsp;&nbsp;</span>Muti-class classifiers</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-vs-all\" data-toc-modified-id=\"One-vs-all-2.6.3.1\"><span class=\"toc-item-num\">2.6.3.1&nbsp;&nbsp;</span>One vs all</a></span></li><li><span><a href=\"#Multi-class-Logistic-Regression\" data-toc-modified-id=\"Multi-class-Logistic-Regression-2.6.3.2\"><span class=\"toc-item-num\">2.6.3.2&nbsp;&nbsp;</span>Multi-class Logistic Regression</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Unsupervised-Learning\" data-toc-modified-id=\"Unsupervised-Learning-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Unsupervised Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#K-means\" data-toc-modified-id=\"K-means-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>K-means</a></span></li><li><span><a href=\"#Density-Based-(DBSCAN)\" data-toc-modified-id=\"Density-Based-(DBSCAN)-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Density Based (DBSCAN)</a></span></li><li><span><a href=\"#Hierarchical-Clustering\" data-toc-modified-id=\"Hierarchical-Clustering-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Hierarchical Clustering</a></span></li></ul></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>PCA</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-detection",
   "metadata": {},
   "source": [
    ">Note: This is organized in a way that makes logical sense by topic, but assumes prior knowledge of the topics (i.e is not chronological in the way it was taught)\n",
    "\n",
    "# General "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-power",
   "metadata": {},
   "source": [
    "Steps of ML:\n",
    "1. Identify the question / task\n",
    "2. Collect data\n",
    "3. Clean and preprocess data: remove/fix crap and noise, make categorical to numerical, feature aggregation\n",
    "4. Exploratory data analysis (EDA): looking at (visualizing) and summary statistics (mean, mode, std dev, frequencies, etc) \n",
    "5. Feature and model selection\n",
    "6. Train model\n",
    "7. Evaluate and communicate results: different error types, speed, etc.\n",
    "8. Deploy working system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-reporter",
   "metadata": {},
   "source": [
    "## Definitions \n",
    "\n",
    "* **Hyperparemeter**: these are the \"knobs\" of the model, they are the parameters that will control complexity, and are passed in by the user\n",
    "* **Model**: a structure that will have fit, and predict functions, this is where all the work happens\n",
    "    1. Training step: \n",
    "        * Input: set of $X$, with corresponding $y$ \n",
    "        * Output: a model that maps from arbitrary $X_i$ to a $y_i$\n",
    "    2. Prediction Step:\n",
    "        * Input: set of $\\tilde{X}$ and a trained model\n",
    "        * Output: predictions $\\tilde{y_i}$ \n",
    "* **Over fitting**: when a model is very complex so that $E_{train} = 0$\n",
    "* **Lazy learning**: when there is no true training phase in a model\n",
    "* **Parametric model**: when there is a **fixed** number of parameters that need to be \"learned\" (we can toss out the training data after)\n",
    "* **Non-parametric model**: when the number of parameters to be learned scales with the dataset (we may need to keep all the training data)\n",
    "* **Curse of dimensionality**: as we increase the number of dimensions (features), need exponentially more points to fill the hyper-sphere\n",
    "* **Data augmentation**: making new data from the existing by providing translations to make model more immune to noise\n",
    "* **Feature selection**: picking which features are important and getting rid of the unimportant ones\n",
    "* **Feature aggregation**: combine features to form new ones, this is useful if there are only a few examples of a particular case \n",
    "* **Feature transformation**: adjusting the data in some way like: discretization (one hot encoding), math transform (scaling or normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-peninsula",
   "metadata": {},
   "source": [
    "## Acronyms \n",
    "\n",
    "* OLS: ordinary least squares\n",
    "* RBF: radial basis function\n",
    "* SVM: support vector machine\n",
    "* MLE: maximum likelihood estimate\n",
    "* MAP: maximum a posteriori\n",
    "* MDS: multi-dimensional scaling\n",
    "* CNN: Convolutional neural network\n",
    "* SGD: stochastic gradient descent\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "* DBSCAN: density-based clustering\n",
    "* KNN: k-nearest neighbors\n",
    "* PCA: principal component analysis\n",
    "* SVD: singular value decomposition\n",
    "* NMF: non-negative matrix factorization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-exhibit",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "![](figs/notation.png)\n",
    "\n",
    "* $X$ is the $(n \\times d)$ *feature matrix*, where $n$ is the number of examples, and $d$ is the number of features.  \n",
    "* $y$ is the *label vector*  (only have this for supervised learning).   \n",
    "* The idea is that we use $X$ to train a model $M$, such that $M(X) = \\hat{y}$, where $\\hat{y}$ is the prediction vector (want $\\hat{y} = y$)\n",
    "\n",
    "* Breaking down the notation:\n",
    "    * $X$: feature matrix\n",
    "    * $X_i$: example $i$ ($i^{th}$ row of $X$)\n",
    "    * $X^j$: feature $j$ ($j^{th}$ column of $X$)\n",
    "    * $X_{ij}$: feature $j$ of object $i$\n",
    "    * $y$: label/output vector\n",
    "    * $y_i$: label/output of object $i$\n",
    "    * $\\hat{y}$: predicted label/output vector ($\\hat{y} = M(X)$)\n",
    "    * $\\tilde{X}$: testing feature matrix (same subscript notation as $X$)\n",
    "    * $\\tilde{y}$: testing label/output vector ($\\tilde{y} = M(\\tilde{X})$)\n",
    "\n",
    "In classification, the training error will come from the number of $\\hat{y_i} \\neq y_i$, but what is even more important is the testing error, which is the number of $\\tilde{y} \\neq y_i$ (i.e how well the model does on data that it has never seen. \n",
    "\n",
    "> Note: often we will use $x_i$ rather than $X_i$ to show that it is a vector we are talking about, but they mean the same thing \n",
    "\n",
    "\n",
    "* Indicies:\n",
    "    * $i$: when we are iterating over the $n$ objects\n",
    "    * $j$: when we are iterating over the $d$ features \n",
    "    * $c$: when we are iterating over $k$ things\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-refund",
   "metadata": {},
   "source": [
    "## Splitting the Data Set\n",
    "\n",
    "* Assume we are given a independent and identically distributed (**IID**) dataset that will be used to train the model.\n",
    "    * Independent: no objects/rows depend on each other\n",
    "    * Identically distributed: from the same distribution\n",
    "    * If this is true, it means that patterns in training and testing data will be the same\n",
    "\n",
    "* From this data, we want to take some to train the model, and some to validate how well the trained model really works (i.e **split** the data). \n",
    "    * Training Data: This is a subset of the original data set that is used to train the model\n",
    "    * Validation Data: This is a subset of the original set that is used to validate that the trained model, it **can also be used for hyperparameter tuning**, but must be careful of optimization bias\n",
    "    * Test Data: This is real world data, this is what we really want our model to be good at handling\n",
    "    \n",
    "![](figs/validation.png)\n",
    "\n",
    "> Validation and testing sets and errors are sometimes used interchangeably. In many cases people wont talk about validation at all, and refer to testing only (which they really mean validation).\n",
    "\n",
    "**Golden Rule of ML**: test/validation data cannot influence the training phase in ANY way\n",
    "\n",
    "**Optimization Bias**: occurs when we minimize the validation error by using validation data to tune hyperparameters\n",
    "* To avoid: **validation data should only be used once, not over and over**, and should definitely not be used a large number of times\n",
    "* If there is optimization bias, it is a good idea to have a 2nd validation set\n",
    "\n",
    "### K-fold Cross Validation\n",
    "\n",
    "* This is a method that allows you to get more out of your data, but at the cost of more computation\n",
    "* Rather than the clean split for training and validation sets as shown above, we can:\n",
    "    1. Split the data into $K$ equal groups\n",
    "    2. Use all but 1 group to train the model, and the remaining group as the validation data\n",
    "    3. Repeat this process $K$ times, so that each of the $K$ groups is used for validation **once**\n",
    "        * Note: Only once to try to avoid optimization bias \n",
    "* **Very commonly used for hyperparameter tuning**\n",
    "    \n",
    "![](figs/kfold.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-estate",
   "metadata": {},
   "source": [
    "## Errors\n",
    "\n",
    "* 3 Types of Errors:\n",
    "    1. Training error ($E_{train}$): this is how well the model predicts on the training set (i.e on data it has seen before)\n",
    "    2. Testing error ($E_{test}$): this is how well the model predicts on the validation set (i.e on data it has not seen before)\n",
    "    3. Approximation error ($E_{approx}$): this is the difference between testing and training error\n",
    "    \n",
    "    \n",
    "**Fundamental Trade off**: only really care about the testing error, a low training error may indicate over fitting\n",
    "$$E_{approx} = E_{test} - E_{train}$$\n",
    "\n",
    "![](figs/tradeoff.png)\n",
    "\n",
    "> This is saying that, when we increase the model complexity, we will decrease $E_{train}$, but not necessarily $E_{test}$. Thus, $E_{approx}$ will increase, signifying over fitting. **What we care about is $E_{test}$**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-honor",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "\n",
    "\n",
    "* We may want to remove outliers, or these may be the most interesting parts of the data. Thus it is useful to have methods to find them\n",
    "* Methods:\n",
    "    * **Model-based**: fit a probabilistic model, outliers are examples with low probability\n",
    "        * Ex: mean and std. deviation and use number of std. dev away from mean\n",
    "        * Drawbacks: these probabilistic models can be sensitive to outliers too, and make assumptions about the data\n",
    "    * **Graphical**: plot the data and a human decides if its an outlier\n",
    "        * Ex: box plot, scatter plot, etc.\n",
    "        * Drawbacks: very ambiguous\n",
    "    * **Cluster-based**: cluster the data, and find points that don't belong to clusters\n",
    "        * Ex: \n",
    "            * K-means: find points far away from any mean, or clusters with a small number of points\n",
    "            * DBSCAN: find points that don't belong to any cluster\n",
    "    * **Supervised learning**: given a dataset with labeled outliers, use supervised learning to predict if new points are outliers\n",
    "        * Drawbacks: need to generate the labeled data set of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-square",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "* Optimization problem: maximizing or minimizing an **objective function**\n",
    "* Example:\n",
    "$$f(x) = (x-a)^2 + b$$\n",
    "    * Minimum: $f^\\star = \\text{min}_xf(x) = \\text{min}_x (x-a)^2 + b = b$ -> This is the minimum value of the $f$\n",
    "    * Minimizer: $x^\\star = \\text{argmin}_xf(x) = \\text{argmin}_x(x-a)^2 + b = a$ -> This is the $x$ value which gives the minimum value of $f$\n",
    "\n",
    "* Constrained optimization: given a objective function, but also a constraint \n",
    "\n",
    "![](figs/minMaxNote.png)\n",
    "\n",
    "> Note: scipy.optimize.minimize takes function f, and guess x0 as parameters, and return the maximum value of f, the maximizer, and other data\n",
    "\n",
    "### Convexity\n",
    "\n",
    "* **Convex function**: a function where if you draw a line between any two points, that line stays on or above the function\n",
    "    * They will not have local min or max, only global $\\implies$ **finding $\\nabla f = 0$ will be the global minimum**\n",
    "    * Careful, as a straight line is considered convex, which has infinite global minimizers and maximizers \n",
    "   \n",
    "* **Determining if a function is convex**:\n",
    "    * d=1: convex if $f''(w) >= 0,  \\forall w$. Can also use the tricks below\n",
    "    * d>1: use theses useful tricks\n",
    "        * Convex function multiplied by a non-negative constant is convex\n",
    "        * Norms and squared norms are convex\n",
    "            * ex: $||w||, ||w||^2, ||w||_1, ||w||_{\\infty}, ||w||_1^2, ...$\n",
    "        * Sum of convex functions is convex (very useful if the elements in the sum are of 1 variable)\n",
    "        * Max of a convex function is convex \n",
    "            * ex: $f(w) = max\\{1, 2w, w^2\\}, w \\in \\mathbb{R}$\n",
    "        * Composition of a convex function and a linear function is convex \n",
    "            * ex: $f(w) = g(Xw - y)$, f is convex if g is convex since $Xw-y$ is linear\n",
    "        * Warning: composition of convex functions may **NOT** be convex, and composition of non-convex ones may be!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-jenny",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "* Idea: find the features (columns) of $X$ that are important (relevant) in predicting $y$. If we can do this we can:\n",
    "    * Determine relevant factors \n",
    "    * Pick best basis functions (regression)\n",
    "    * Know the best types of data to collect\n",
    "    * Speed up computation\n",
    "* This is one of the most important problems in ML, but its messy\n",
    "\n",
    "### Typical methods\n",
    "* **Association**: compute correlation between $x_{*, j}$, and $y$\n",
    "    * Flaws: ignores variable interactions\n",
    "* **Regression weights**: fit weight vector $w$, and select features where $|w_j|$ is greater than a threshold\n",
    "    * Flaws: collinearity in X means that solutions aren't unique\n",
    "        * If two features are the exact same, they can have massive weights but cancel each other out\n",
    "        * If two features are the exact same, could choose only one of them, which might be the the non-relevant one\n",
    "        * Normalization can fix with flaw (and $L_0$ can do the selection for us!)\n",
    "* **Search and score**: define a score function $f(S)$ that measures quality of a set of features $S$, now search for a set $S$ with the best score. I.e compute the score of every possible permutation of features\n",
    "    * Flaws: $O(2^d)$ models, thus large optimization bias, time complexity, and also prone to false positives (statistically)\n",
    "    * The score is usually selected to be validation error (CANT BE TRAINING, as this would just overfit and select all values)\n",
    "        * Could also add a penalty for the number of features (to prefer less complex models), very much like regularization (using the loss function as the score, and adding penalty is L0 regression!)\n",
    "* **Forward selection**: greedy search and score, build up the relevant features based on adding which one next is best\n",
    "    * $O(d^2)$ models, which is much better than search and score, and less overfitting\n",
    "* **L0/L1 regularization**: this will do the feature selection for us by setting weights to **exactly** 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-salmon",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "* It is common to standardize features by subtracting their means and deviding by the variance:\n",
    "    * DONT standardize the y-intercept, doesn't really make sense\n",
    "\\begin{align*}\n",
    "    x_{ij} &= \\frac{x_{ij} - \\mu_j}{\\theta_j} \\\\\n",
    "    \\mu_j &= \\frac{1}{n} \\sum_{i=1}^n x_{ij} \\\\\n",
    "    \\theta_j &= \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n (x_{ij} - \\mu_j)^2}\n",
    "\\end{align*}\n",
    "\n",
    "* Can also standardize the targets (features) in a similar manor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-batman",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "* with 1 hyperparameter, can use k-fold cross validation (see section above)\n",
    "* With multiple, it is more complex because there are not many more possible values, and overfitting/optimization bias may be a problem. These are a few simple methods:\n",
    "    * Exaustive search: try all combinations among a fixed set (GridSearchCV in Scikit learn)\n",
    "    * Random search: try random values (RandomizedSearchCV in Scikit learn)\n",
    "    * This now means there is:\n",
    "        * loop over hyperparameters\n",
    "            * loop k fold cross validation\n",
    "                * look gradient descent to train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-spouse",
   "metadata": {},
   "source": [
    "## Recommender Systems\n",
    "\n",
    "* Amazon product recommender system: the goal is to recommend a product, given another product\n",
    "    * User product matrix: the matrix we use for a recommender system is a bit different:\n",
    "        * $X_i$: this is all products bought by user $i$ \n",
    "        * $X^j$: this gives all the users that bought product $j$\n",
    "        * I.e the rows are the users, and the features are the product, $X_{ij} = 1$ means user $i$ bought product $j$\n",
    "    * Find the KNN's across **columns** (normally KNN is done across rows)\n",
    "        * Can define distance as euclidean, or cosine similarity\n",
    "* There are 2 main types:\n",
    "    1. Collaborative filtering (Unsupervised): recommend product given another product\n",
    "        * Goal is to fill in a user-item matrix, this is the same as the user product matrix, but now we have ratings in the entries\n",
    "            * The matrix has missing entries (when a user doesn't rate the product), thus we want to try to fill these in\n",
    "        * We can use a latent factor model to fill in the missing stuff (setting missing things to 0)\n",
    "            * Note that we cant use SVD for PCA due to the missing entries\n",
    "        * Drawback: can't predict on new users/movies\n",
    "    2. Content-based filtering (Supervised): recommend product given a user\n",
    "        * We can use a normal linear model approach:\n",
    "            $$\\hat{y} = w^T X_{ij}$$\n",
    "            * Note that $X_{ij}$ is a vector of features for the movie/user pairing \n",
    "        * This is like collaborative filtering, but it extends it as it now can compare with similar users (not just with movies)\n",
    "        * Benefit: can learn new users/movies\n",
    "        * Drawback: can't learn about each user/movie\n",
    "* Could add these method together, and add different types of regularization\n",
    "* Neural network based models are now typically used as they generally perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-morning",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-internship",
   "metadata": {},
   "source": [
    "* Models that train on labeled data (the labels $y$ are the \"supervisors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-manchester",
   "metadata": {},
   "source": [
    "## Decision Tree \n",
    "\n",
    "**Hyperparameters**: Max depth  \n",
    "**Model type**: Non-parametric (but a bit blurred)  \n",
    "**Runtime**: Train: $O(nd\\log(n))$, Predict: $O(\\text{tree depth})$\n",
    "\n",
    "> Note: Looking at classification decision tree only (class labels), there also exists regression trees but are not covered here\n",
    "\n",
    "* Greedy (local optimal decision), recursively defined model of decision stumps for categorical labels (i.e classification)\n",
    "* Idea: \n",
    "    * Decision stump input is a dataset, and the stump splits that into two parts based on a feature threshold value (need to find the best feature and threshold to split on in training)\n",
    "    * Feed the two output datasets into another stump\n",
    "    * Leaf stumps will have the classification\n",
    "    \n",
    "<img src=\"figs/simpleTree.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "**Stump Algorithm**:\n",
    "* For each feature: -> O(d)\n",
    "    * Sort features -> O(nlgn)\n",
    "    * For each threshold (i.e, each value in the features set): -> O(n)\n",
    "        * Generate outputs from rule -> O(1): We store the previous counts, and shift 1 sorted object and update\n",
    "        * Compute score function and update best if that is better than previous best -> O(1)\n",
    "* Pick the rule that had the best score\n",
    "\n",
    "\n",
    "**Tree Algorithm**: \n",
    "* Feed the output of one stump into a new stump and train it on that subset of data\n",
    "* Stop splitting once the max depth is reached, or it gives no better score than we had before\n",
    "\n",
    "\n",
    "**Score functions**:\n",
    "* Accuracy: use the prediction accuracy as the score (this is the naive approach)\n",
    "$$ \\text{accuracy} = \\text{count}(y_i \\neq \\hat{y}_i) $$\n",
    "    * There may be no possible split to increase accuracy, although it may decrease entropy (randomness)\n",
    "* Information gain: much better approach\n",
    "\\begin{align*}\n",
    "    \\text{Info gain} &= \\text{entropy}(y) - \\frac{n_{sat}}{n} \\text{entropy}(y_{yes}) - \\frac{n_{not}}{n} \\text{entropy}(y_{not}) \\\\\n",
    "    \\text{entropy}(y) &= -\\sum_{i=1}^n P(y_i) \\log P(y_i)\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "![](figs/entropy.png)\n",
    "\n",
    "\n",
    "In this image above, using accuracy score would not split this set, but using information gain will and reduce the error after completion\n",
    "\n",
    "\n",
    "A decision tree splits the input space into sections, where within that section a specific output will be selected. Notice that splits are straight lines.\n",
    "![](figs/decisionTreeOutputSpace.png)\n",
    "\n",
    "**Comments**:\n",
    "* Decision trees will product 0 test error by crazy over fitting so long as there are no duplicates with different labels\n",
    "    * Deeper depth is a more complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-mystery",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "**Hyperparameters**: k -> the number of nearest neighbors to consider  \n",
    "**Model type**: Non-parametric (must keep entire training set)   \n",
    "**Runtime**: Train: $O(1)$ (lazy learning), Predict: $O(nd)$ (for each object in the training set, must compute euclidean distance)\n",
    "\n",
    "\n",
    "* Idea: given an input object (vector), find the $k$ nearest distance points from the training set to that object. Take the label for this object to be the most mode of those neighbors\n",
    "* Distance function: typically euclidean distance / L2 norm\n",
    "\n",
    "Knn will split the output space in more interesting ways that decision trees.\n",
    "![](figs/knnOutputSpace.png)\n",
    "\n",
    "**Comments**:\n",
    "* Run into problems if features have very different scales\n",
    "* $k=1$ will have no test error (unless duplicates with different labels)\n",
    "* Can think of $k$ like a slider on how much we trust out data. Low $k$ means we really trust it, high $k$ means we don't trust it at all\n",
    "    * Smaller $k$ is a more complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-diagram",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "**Hyperparameters**: $\\beta$ -> Laplace smoothing parameter   \n",
    "**Model type**: Parametric (but again, it is a bit fuzzy because the number of parameters we need to store does depend on the data, but doesn't scale with more data)  \n",
    "**Runtime**: Train: $O(nd)$ (one pass over the data to count), Predict: $O(dk)$ (for each example)\n",
    "\n",
    "A probabilistic classifier with a few tricks to simplify computation\n",
    "\n",
    "**Derivation**:\n",
    "* Start with Bayes Rule: $P(y_k | x_i) = \\frac{P(x_i | y_k)P(y_k)}{P(x_i)}$, where $P(y_k) = \\frac{\\text{# of times } y_k \\text{ appears in} y}{n}$ \n",
    "    * That is, given $x_i$ give the probability of the classification $y_k$\n",
    "    * Idea is to compute this for each possible classification, and take the highest probability one as the classifier\n",
    "* Drop the $P(x_i)$ from the denominator: we only are about which has the highest probability, they will all have the same denominator, so lets not bother trying to compute it\n",
    "* Naive part: assume $P(x_i|y_k) = \\prod_{j=1}^d P(X_{ij} | y_k)$, and we know that $P(X_{ij} | y_k) = \\frac{\\text{# of times } X_{ij} \\text{ occurs with label } y_k}{\\text{number of labels of } y_k \\text{ in } y}$\n",
    "    * I.e we assume conditional independence, which is likely not true, but this is less strong of an assumption than complete independence\n",
    "* Introduce Laplace Smoothing:\n",
    "    * Problem: if the # of $X_{ij}$ occurrence with label $y_k$ is $0$, this kills the sum\n",
    "    * Solution: $P(X_{ij} | y_k) = \\frac{\\text{# of times } X_{ij} \\text{ occurs with label } y_k + \\beta}{\\text{number of labels of } y_k \\text{ in } y + c \\beta}$\n",
    "        * $\\beta$: Laplace smoothing parameter (typically 1)\n",
    "        * $c$: # of possible values $X_{ij}$ can take on (typically 2)\n",
    "\n",
    "\n",
    "**Algorithm**:\n",
    "* Train:\n",
    "    * Compute and store $P(y_k)$, $P(X_{ij} | y_k)$\n",
    "    \n",
    "* Predict:\n",
    "    * For each possible label $y_k$, compute the following, and predict the label with the highest probability\n",
    "\\begin{align*}\n",
    "P(y_k | x_i) &= P(y_k) \\prod_{j=1}^d P(X_{ij} | y_k) \\\\\n",
    "P(X_{ij} | y_k) &= \\frac{\\text{# of times } X_{ij} \\text{ occurs with label } y_k + \\beta}{\\text{number of labels of } y_k \\text{ in } y + c \\beta}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "**Comments**:\n",
    "* $\\beta$ is like you have seen $\\beta$ of everything before\n",
    "    * It is like a slider on how much you trust the data (high $\\beta$ being less trust)\n",
    "        * Smaller $\\beta$ is a more complex model\n",
    "* Can use decision theory to add a cost to each output, to bias the model to pick some thing over others\n",
    "    * Ex: it is much worse to falsely predict a spam email than to miss one, so the cost of predicting spam would be high\n",
    "* With new labeled data, we can just update the counts (it is easy to add to, unlike many other ML models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-studio",
   "metadata": {},
   "source": [
    "\n",
    "## Ensemble Methods\n",
    "\n",
    "* Classifiers that have classifiers (KNN, decision tree, Bayes, etc) as inputs. AKA meta-learning\n",
    "* Often have higher accuracy than the input classifiers\n",
    "* Goal: significantly improve $E_{test}$ or $E_{approx}$ without doing much worse on the other one\n",
    "    * Like \"hacking\" the fundamental trade off\n",
    "\n",
    "\n",
    "### Averaging\n",
    "\n",
    "* Make the output the average of the outputs from the other models\n",
    "* Often performs better than individual models (i.e multiple ok models can make a great model)\n",
    "* Works because many classifiers will overfit, but do so independently, this reduces the overfitting and gets closer to the true prediction\n",
    "\n",
    "### Stacking\n",
    "\n",
    "* Create a new data set which is the output of different models given the same initial training set\n",
    "* Use that data set, and the true label as the inputs to another model (ex. decision tree) for generating the predicted label\n",
    "![](figs/stacking.png)\n",
    "\n",
    "\n",
    "### Random Forests\n",
    "\n",
    "**Hyperparameters**: \n",
    "* Number of features to sample for random tree stumps\n",
    "* Random tree max depth\n",
    "\n",
    "* This is one of the best ML algorithms that just works out of the box!\n",
    "* Average a set of deep **random decision trees** which we **bootstrap** \n",
    "    * Idea is that this will create trees which make independent errors, and the average will be more optimal than even the best decision tree we could train\n",
    "\n",
    "**Bootstrapping**: pick a set of $n$ object from the initial dataset chosen independently with replacement \n",
    "* Can have duplicates\n",
    "* This gives us different datasets for each one of the trees we are going to average with\n",
    "* This is from statistics\n",
    "\n",
    "**Bagging**: using bootstrap samples for ensemble learning\n",
    "\n",
    "**Random decision tree**: for each stump split, randomly sample a small number (a subset) of the features and only consider those when searching for optimal split\n",
    "* This will produce a less than optimal tree\n",
    "\n",
    "\n",
    "Random forests can product crazy looking output spaces which a regular decision tree could not make\n",
    "![](figs/randomForest.png)\n",
    "\n",
    "\n",
    "> There are many more ensembles methods which aren't covered here, like boosting, cascading, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-mandate",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "* Unlike classification, regressions methods will return a numerical value in $y$ rather than a classifier (i.e $y_i$ is no longer discrete)\n",
    "* Idea is to train a **linear** model to learn the weights $w$ (vector) such that:\n",
    "    $$\\hat{y}_i = w x_i = w_1x_{i1} + w_2 x_{i2} + ... + w_d x_{id}$$\n",
    "![](figs/1dreg.png)\n",
    "* To learn the weights, we need to **find the minimizer $w$ of the loss function $f(w)$ for our model** \n",
    "* **3 steps to specifying regression**\n",
    "    1. Choose the model (the basis function)\n",
    "    2. Choose the loss function\n",
    "    3. Choose the optimization method\n",
    "* There is an issue of uniqueness here, if $X$ is collinear, or in the simpler case of duplicate feature columns this means that the weight of one feature can be increased, while the other is decreased without changing the prediction \n",
    "    * I.e: the solution is not unique\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-revolution",
   "metadata": {},
   "source": [
    "### Loss Functions\n",
    "\n",
    "* The loss function is the thing we try to optimize to find the regression weights $w$ ($v$ if change of basis). \n",
    "* The loss function will give us a cost for each set of the weights $w$, we can visualize this in parameter and data space\n",
    "    * Each point in parameter space gives us a new model, which is the orange line in data space\n",
    "    * Contours in parameter space are the values of the loss\n",
    "    * With a convex function, there is a global minimum which we are trying to find (the red star), as we move our model parameters (blue star) towards the red star we are minimizing the loss function and have a \"good\" fit (based on the particular loss function)\n",
    "![](figs/parameterDataSpace.png)\n",
    "\n",
    "\n",
    "#### L2 Loss Function (least squares)\n",
    "$$f(w) = \\frac{1}{2}||Xw-y||_2^2 = \\sum_{i=1}^n (wz_i - y_i)^2$$\n",
    "* This is non-robust regression (very sensitive to outliers)\n",
    "* Convex, differentiable, and leads to beautiful, closed form normal equations, which can be directly solved (see the section on optimization methods)\n",
    "* Leading coefficient $\\frac{1}{2}$ is just here for convenience (see the normal equations) \n",
    "    \n",
    "\n",
    "#### L1 Loss Function (robust regression)\n",
    "$$f(w) = ||Xw-y||_1 = \\sum_{i=1}^n |wz_i - y_i|$$\n",
    "* This is robust to outliers\n",
    "* Convex, but not differentiable, which causes problems for optimization methods\n",
    "* Can approximate as differentiable:\n",
    "    * **Huber Loss**: approximate this as a quadratic near the point of nondifferentiability, and use absolute value function away from that\n",
    "\\begin{align*}\n",
    "    f(w) &= \\sum_{i=1}^n h(wz_i - y_i) \\\\\n",
    "    h(z) &= \\frac{1}{2} z^2 \\text{  if  } |z| \\leq 1, \\text{  else  } |z|-\\frac{1}{2}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "#### L$\\infty$ Loss Function (another robust regression)\n",
    "$$f(w) = ||Xw-y||_{\\infty} = \\text{max}(Xw-y) \\approx \\log(\\sum_{i=1}^n \\exp(Xw-y))$$\n",
    "* Idea is to approximate the max function (convex, but not differentiable) using log-sum-exp\n",
    "    * This works because the sum of the exp will be dominated by largest, and the log will give the result\n",
    "    * Won't work that well if the values are very close to begin with\n",
    "    \n",
    "    \n",
    "    \n",
    "> A note on robustness, non-convex functions are even more robust, but very hard to optimize. The absolute value is the \"most robust\" convex loss function\n",
    "![](figs/robustness.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-graph",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "* Idea: add a penality to the complexity of the model, this encourages smaller regression weights\n",
    "* $\\lambda$: hyperparameter which controls how much regularization to apply\n",
    "    * $\\lambda = 0$: no regularization -> saying we completely trust the data\n",
    "    * $\\lambda = \\infty$: max regularization, this will cause all weights to be 0 -> saying we don't trust the data at all\n",
    "\n",
    "\n",
    "#### Types\n",
    "\n",
    "Let $g(w)$ be the initial loss function (without regularization)\n",
    "\n",
    "* **L2**: $f(w) = g(w) + \\frac{\\lambda}{2} \\sum_{j=1}^d w_j^2 = g(w) + \\frac{\\lambda}{2} ||w||^2$\n",
    "    * Can use normal equations\n",
    "    * Will make less relevant feature weights low, but not zero (won't do selection)\n",
    "    * Solution is unique\n",
    "\n",
    "* **L1**: $f(w) = g(w) + \\lambda \\sum_{j=1}^d |w_j| = g(w) + \\lambda ||w||_1$\n",
    "    * Can't use normal equations\n",
    "    * Sets non-relevant feature weights to exactly zero\n",
    "    * Solution is not unique\n",
    "    * It is not smooth (can't use gradient descent, but there are other methods), but it is precisely this which causes exactly zero weights\n",
    "    * Simultaneously regularizes and does feature selection\n",
    "\n",
    "* **L0**: $f(w) = g(w) + \\lambda |w_j|_0$\n",
    "    * Basic penalty to number of non-zero terms\n",
    "    * Not continuous, means we can't use typical optimization methods, but can use search and score (see feature selection section)\n",
    "\n",
    "\n",
    "#### Typical loss functions and regularizations\n",
    "* **Information criteria (AIC, BIC)**: $f(w) = ||Xw-y||^2 + \\lambda ||w||_0$\n",
    "    * L2 loss with L0 regularization\n",
    "* **Ridge regression**: $f(w) = ||Xw-y||^2 + \\frac{\\lambda}{2}||w||^2$\n",
    "    * L2 loss with L2 regularization\n",
    "* **LASSO**: $f(w) = ||Xw-y||^2 + \\lambda ||w||_1$\n",
    "    * L2 loss with L1 regularization\n",
    "\n",
    "\n",
    "\n",
    "![](figs/regPaths.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-light",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Estimate (MLE) and Maximum A Priori (MAP)\n",
    "\n",
    "* This gives an alternative interpretation, or a derivation of the loss functions typically used based on probabilities \n",
    "* Background:\n",
    "    * If $w$ is the probability of flipping heads, then the probability of getting $k$ heads in $n$ flips is given by: $P(k|n, w) = nCk w^k (1-w)^{n-k}$\n",
    "    * If we don't know $w$, we can observe the data and try to predict it: $g(w) = P(k | n, w$, where we observe $k, n$\n",
    "    * We can plot $g(w)$, and find the maximum likelihood $w = \\hat{w}$, i.e the $w$ that proves the higher probability of observing $D$ (data)\n",
    "    * $\\hat{w} = \\text{argmax}_w (P(D|w)) = \\text{argmin}_w(-\\log(P(D|w))$\n",
    "        * Since $\\log$ is monotonic\n",
    "* **MLE**: \n",
    "    $$f(w) = NLL(w)$$\n",
    "    * If data is IID $\\implies P(D|w) = \\prod_{i=1}^n P(D_i|w)$\n",
    "    * Thus, $\\hat{w} = \\text{argmax}_w(\\prod_{i=1}^n P(D_i|w)) = \\text{argmin}_w (-\\sum_{i=1}^n \\log(P(D_i|w)))$\n",
    "        * That is, the best $\\hat{w} = \\text{argmin}_w(f(w))$ comes from minimizing the negative log likelihood (NLL)\n",
    "        * This is how we get to the equation $f(w) = NLL(w)$ above\n",
    "    * So, given $P(y_i|x_i, w)$ we can find the loss function\n",
    "        * Logistic loss: $P(y_i|x_i, w) = h(y_iw^Tx_i)$, where $h$ is the sigmoid function\n",
    "        * L2 loss: $P(y_i|x_i, w) = $ normal with mean $w^Tx_i$\n",
    "            * $y_i = w^Tx_i + \\epsilon_i$, where $\\epsilon_i$ is sampled from std. normal (thus, $w^Tx_i$ is the mean)\n",
    "        * L1 loss: same as L2, but with $\\epsilon_i$ sampled from a laplace pdf\n",
    "            * The longer the tails of the pdf we are sampling from, the less the outliers impact (i.e they are okay), this is why L1 is robust\n",
    "    * Problem: this leads to overfitting, data could be very likely for some unlikely $w$ \n",
    "* **MAP**: solves the problem in MAP, by adding an a priori (assumption) for $w$\n",
    "\\begin{align*}\n",
    "    P(w|D) &\\propto P(D|w)P(w) \\\\\n",
    "   \\hat{w} &= \\text{argmax}_w \\prod_{i=1}^n P(D_i|w)P (w) = \\text{argmin}_w \\left[ - \\sum_{i=1}^n \\log(P(D_i|w)) - \\sum_{j=1}^d \\log(P(w_j)) \\right] \\\\\n",
    "   \\implies f(w) & = NLL(w) = - \\sum_{i=1}^n \\log(P(D_i|w)) - \\sum_{j=1}^d \\log(P(w_j))\n",
    "\\end{align*}\n",
    "* The 1st term in NLL$(w)$ is the loss function, and the 2nd term is the regulizer!\n",
    "    * Choice of $P(D|w)$ corresponds to the loss\n",
    "    * Choice of $P(w)$ corresponds to the regularization\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-outside",
   "metadata": {},
   "source": [
    "### Optimization Method: Finding Loss Function Minimizer (regression weights)\n",
    "\n",
    "* The idea is that we have some convex loss function (global minimum only), and we want to find the minimizer\n",
    "    * To do so, we can use the gradient, we want to find where this is 0\n",
    "* Common gradients: $c$ is a constant, $b$ is a vector, $A$ is a **symmetric** matrix\n",
    "\\begin{align*}\n",
    "    \\nabla_w(c) &= 0 \\\\\n",
    "    \\nabla_w (w^Tb) &= b\\\\\n",
    "    \\nabla_w (w^TAw) &= 2Aw\n",
    "\\end{align*}\n",
    "\n",
    "> Note: There are many other methods for optimization, these are the easiest to teach or most popular\n",
    "\n",
    "\n",
    "#### Normal Equations\n",
    "$$X^TXw=X^Ty$$  \n",
    "\n",
    "* **Runtime**: $O(nd^2 + d^3)$\n",
    "* These come from the setting the gradient of the least squares loss to 0\n",
    "\\begin{align*}\n",
    "    f(w) &= \\frac{1}{2} \\sum_{i=1}^n (w z_i - y_i)^2, \\text{note the leading 1/2, this is just for convenience} \\\\\n",
    "    &= \\frac{1}{2}||Xw-y||^2 \\\\\n",
    "    &= \\frac{1}{2}(Xw-y)^T(Xw-y) \\\\\n",
    "    &= \\frac{1}{2}(w^TAw-2w^Tb+c), A=X^TX, b=x^Ty \\\\\n",
    "    \\nabla f(w) &= X^TXw-X^Ty, \\text{using the common gradients above} \\\\\n",
    "    \\nabla f(w) &= 0 \\implies X^TXw=X^Ty\n",
    "\\end{align*}\n",
    "\n",
    "* Note that $X^TX$ may not be invertible, thus the inverse may not exist. We must use different methods to find the solution (many libraries for this)\n",
    "* Solution may not be unique due to collinearity in $X$\n",
    "\n",
    "#### Gradient Descent\n",
    "$$w^{t+1} = w^t - \\alpha^t \\nabla f(w^t)$$\n",
    "\n",
    "* **Runtime**: $O(ndt)$  \n",
    "    * $t$: iteration number\n",
    "    * $\\alpha$: learning rate\n",
    "* Unfortunately, it is rarely the case the the loss function will have a closed form solution like with the normal equations, thus we need another method. Enter gradient descent\n",
    "\n",
    "* Idea: \n",
    "    1. Start with a random weight $w^0$\n",
    "    2. Nudge these in the direction of the $-\\nabla f(w^t)$ to find $w^{t+1}$\n",
    "    3. Repeat this until it converges (or changes less than a threshold between iterations)\n",
    "* If the function is convex, we will find a (or the) global minimum\n",
    "* Gradient descent iterations moves the blue star closer the the minimum (red star), until it converges there\n",
    "![](figs/gradientDescent.png)\n",
    "\n",
    "#### Stochastic Gradient Descent\n",
    "\n",
    "$$w^{t+1} = w^t - \\alpha^t \\nabla f_i(w^t)$$\n",
    "\n",
    "* This is the most popular optimization method in deep learning!\n",
    "* Steps:\n",
    "    1. Generate random integer $i$ (or batch)\n",
    "    2. Compute the gradient with $f_i$, or the batch\n",
    "    3. Update parameters with the equation above\n",
    "* Like gradient descent, but the idea is to only compute it on a random subset of the training examples to iterate much faster \n",
    "    * This is like taking much faster, less optimal steps, but in practice converges quicker\n",
    "    * The equation above has it only for training example $i$, but could be on a \"mini batch\" of examples\n",
    "* Works for any loss function in which we can divide by $n$ without changing the location of optimal $w$. When this is the case (it usually is), we can say that:\n",
    "\\begin{align*}\n",
    "    F(w) &= \\frac{1}{n} \\sum f_i(w) \\\\\n",
    "    \\nabla_w F(w) &=  \\nabla_w \\frac{1}{n} \\sum f_i(w) = \\frac{1}{n} \\sum \\nabla_w f_i(w)\n",
    "\\end{align*}\n",
    "    * Thus, the average of gradients, is the gradient\n",
    "    * Then, taking all these small steps in the direction of the partial gradients (only 1 or feature, or a mini batch) will be the same as taking big steps in the direction of the complete gradient\n",
    "    * **On average, this moves in the right direction**\n",
    "* We must decrease the step size as we converge to the optimal $w = w^*$ to avoid erratic behavior around $w^*$ due to variance in the partial gradients. So, split this into 2 parts:\n",
    "    1. Fast convergence to a ball around $w^*$\n",
    "    2. Shrink step size to converge to/near $w^*$\n",
    "* Best step size in theory (not to slow, not to fast):\n",
    "    * Can get everywhere: $\\sum_{t=1}^{\\infty} \\alpha^t = \\infty$\n",
    "    * Effects of variance go to zero: $\\sum_{t=1}^{\\infty} (\\alpha^t)^2 = \\infty$\n",
    "        * $\\alpha^t$: this is the step size of iteration $t$\n",
    "    * $\\alpha^t = O(\\frac{1}{t}$ satifies these conditions, but works poorly in practice\n",
    "* Good step sizes in practice:\n",
    "    * $O(\\frac{1}{\\sqrt{t}})$\n",
    "    * $O(1)$\n",
    "    * Average over the second half of iterations: $\\bar{w}^t = \\frac{1}{t/2} \\sum_{k=t/2}^t w^k$\n",
    "* **Minibatches**:\n",
    "    * Iteration: one update of $w$\n",
    "        * In regular GD it looked at $n$ examples per iteration\n",
    "    * Epoch: number of iterations it takes to pass through the whole training set\n",
    "        * If minibatch size is 1: $n$ iterations\n",
    "        * If minibatch size it 10: $\\frac{n}{10}$ iterations\n",
    "        * Regular GD took 1 iteration\n",
    "        * This is a meaningful way to measure how much work we did, 2 epoch means that you looked through the whole data set twice, where as 1000 iterations of SGD is less meaningful (could be 1000 epoch if the minibatch size is the entire set, i.e regular GD)\n",
    "\n",
    "\n",
    "#### Projected Gradient Descent\n",
    "* This is just normal gradient descent, but we impose a non-negativity condition at each step. Meaning that $w$ will be non-negative, which is useful in some applications (ex. NMF)\n",
    "\\begin{align*}\n",
    "    w^{t + \\frac{1}{2}} &= w^t - \\alpha^t & \\text{this is the normal gradient descent step, call it t+1/2 as its half way point in the projected step} \\\\\n",
    "    w_j^{t+1} &= \\max(0, w_j^{t+\\frac{1}{2}}) & \\text{this is where we impose non-negativity}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-skirt",
   "metadata": {},
   "source": [
    "### Change of basis\n",
    "* Idea: modify $X$ to provide different, nonlinear basis which can give us more complex (nonlinear) fits! The beauty here is **once we specify this basis function, everything else works**. We now have:\n",
    "\\begin{align*}\n",
    "    X &\\to Z \\\\\n",
    "    w &\\to v, \\text{where v is the (kx1) weight vector} \\\\\n",
    "    \\hat{y}_i &= v z_i = v_1 z_{i1} + v_2 z_{i2} + ... + v_k z_{ik}\n",
    "\\end{align*}\n",
    "\n",
    "* **Important Comments**:\n",
    "    * Can combine different basis to create very complex functions (and models)\n",
    "    * ANYTHING WE DO TO X to form Z, WE MUST DO TO THE TEST DATA ALSO\n",
    "        * i.e $X \\to Z \\implies \\tilde{X} \\to \\tilde{Z}$\n",
    "\n",
    "#### y-intercept\n",
    "* Can add y-intercept by adding a column of 1's to $X$ to form a new set $Z$\n",
    "    ![](figs/yintercept.png)\n",
    "\n",
    "\n",
    "#### Degree p polynomial\n",
    "* Can have a polynomial fit by taking powers of columns in $X$ to form $Z$\n",
    "    ![](figs/degreep.png)\n",
    "    > Note: this image shows $d=1$, for higher $d$ you would also have cross terms (i.e $x_{i1}^2, x_{i2}^2, x_{i1}x_{i2})$\n",
    "    ![](figs/changeOfBasis.png)\n",
    "\n",
    "#### Periodic bases\n",
    "* Instead of polynomials we could use a periodic basis like sin or cos\n",
    "\n",
    "#### Gaussian radial basis function (RBF)\n",
    "* Here we use $n$ Gaussian bumps as the basis, with hyperparameter $\\sigma$ controlling width (smaller width means more complex model), centered at each training example \n",
    "![](figs/rbf.png)\n",
    "$$g(\\epsilon) = \\exp(- \\frac{\\epsilon^2}{2 \\sigma^2})$$\n",
    "    * this is a **nonparametric model**, must store the entire dataset\n",
    "    * could also add a bias (y-intercept) and a linear basis to this\n",
    "\n",
    "#### Kernel Trick\n",
    "\n",
    "* When we change basis from $X \\to Z$, $Z$ may be too big to store in memory, but this is a clever way to get around that\n",
    "* We can rewrite the normal equations in an alternative way, which is faster to compute if $d > n$\n",
    "\\begin{align*}\n",
    "    \\text{Regular: } w &= (X^TX + \\lambda I)^{-1}X^TY \\to O(nd^2+d^3) \\\\\n",
    "    \\text{Alternative: } w &= X^T(XX^T + \\lambda I)^{-1}y \\to O(n^2d+n^3)\n",
    "\\end{align*}\n",
    "* Gram Matrix (K): \n",
    "    * $K = XX^T$, this is a $(n \\times x)$ matrix with elements $K_{ij} = <x_i, x_j>$ (elements are dot products between training examples)\n",
    "    * $\\tilde{K} = \\tilde{X}X^T$, this is like the Gram matrix, but is with a test set $\\tilde{X}$, it is a $(t \\times n)$ matrix with elements $K_{ij} = <\\tilde{X}_i, X^j>$\n",
    "* Transformation: $X \\to Z$, $K \\to ZZ^T$, $w \\to v$\n",
    "\\begin{align*}\n",
    "    \\implies v &= Z^T(ZZ^T + \\lambda I)^{-1}y \\\\\n",
    "    \\hat{y} &= \\tilde{Z}v = \\tilde{Z}Z^T(ZZ^T + \\lambda I)^{-1}y \\\\\n",
    "    &= \\tilde{K}(K+\\lambda I)^{-1}y\n",
    "\\end{align*}\n",
    "    * $\\hat{y}$ is $(t \\times 1)$\n",
    "    * $\\tilde{K}$ is $(t \\times x)$\n",
    "    * $(K + \\lambda I)$ is $(n \\times x)$\n",
    "    * Thus, even if $d$ or $k$ is so big it won't fit into memory, we can compute this if we can find $K$ and $\\tilde{K}$\n",
    "* Kernel trick: $K = k(x_i, x_j)$, and $\\tilde{K} = \\tilde{k}(\\tilde{x}_i, x_j)$\n",
    "    * If we can find the kernel function $k(x_i, x_j)$, then we solve the problem\n",
    "* Common kernels:\n",
    "    * Polynomial basis (degree $p$): $k(x_i, x_j) = (1+x_i x_j)^p$\n",
    "    * Gaussian RBF kernel: $k(x_i, x_j) = \\exp(- \\frac{\\|x_i - x_j\\|^2}{2 \\sigma^2})$\n",
    "        * $\\sigma$: hyperparameter\n",
    "        * The basis formed by this kernel would be infinite dimensional (but like the Gaussian RBF basis)\n",
    "\n",
    "> Note: as long as we can define an inner product between kernels (similarity), we can do this (doesn't need to be numerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-paint",
   "metadata": {},
   "source": [
    "## Linear Classifiers\n",
    "\n",
    "* Idea: use what we know about regression, but make it work for linear classifiers. The classifier will be a hyperplane splitting the space in half (points on one side have predicted labels of +1, ones on the other have -1)\n",
    "* Steps:\n",
    "    1. Encode $y_i \\in {-1, 1}$\n",
    "        * Note: statistics uses ${0, 1}$, which makes uglier loss functions\n",
    "    2. Use sign$({w^Tx_i})$ as prediction\n",
    "        * This is just the sign of the prediction\n",
    "    3. Can use sigmoid$(w^Tx_i)$ and interpret this as a probability\n",
    "          \n",
    "* Can't just use least squares, or other loss functions from regression as this will penalize the model for being \"too right\". Need a new loss function:\n",
    "\n",
    "![](figs/linearClassifierLosses.png)\n",
    "\n",
    "* **Logistic loss**: $f(w) = \\log(1+\\exp(-y_iw^Tx_i)$\n",
    "* **Hinge loss**:   $f(x) = \\sum_{i=1}^n \\max(0, 1-y_iw^Tx_i)$\n",
    "    * Puts the hinge at a positive value to avoid trivial solution of $w=0$\n",
    "    * Notice that if $y_iw^Tx_i$ > 1, the example $x_i$ doesn't contribute to the loss. Examples that contribute to the loss are called **support vectors**\n",
    "    * This is an upper bound on the 0-1 loss\n",
    "\n",
    "\n",
    "### Logistic Regression:\n",
    "* Uses the logistic loss:\n",
    "    $$f(w) = \\log(1+\\exp(-y_iw^Tx_i)$$\n",
    "    * Should also add regularization to this!\n",
    "    * Convex and differentiable $\\implies$ can optimize with gradient descent\n",
    "    * It is a smooth, convex approximation to the 1-0 loss (add one if its wrong, add 0 if its right)\n",
    "    \n",
    "\n",
    "### Support Vector Machine (SVM):\n",
    "* Uses the hinge loss with L2 regularization:\n",
    "    $$f(x) = \\sum_{i=1}^n \\max(0, 1-y_iw^Tx_i) + \\frac{\\lambda}{2}||w||^2$$\n",
    "    * Again, note that the support vectors are the only ones that contribute to the loss. Retraining with only those vectors will give us the same model!\n",
    "    * This is non-differentiable, but there are methods to optimize\n",
    "    * This actually maximized the margin (space from regression plane to the nearest points)\n",
    "    \n",
    "\n",
    "\n",
    "### Muti-class classifiers\n",
    "* When $y_i$ can take on more classes than just ${-1, 1}$, we can still handle it\n",
    "* Notation:\n",
    "    * Assume $y_i$ can take on $k$ classes\n",
    "    * We store weight vectors for each class in a $W$ matrix\n",
    "    * $w_c$ is the weight vector in row $c$ of the $W$\n",
    "    * $w_{y_i}$ is the classifier constructed for $c=y_i$\n",
    "\n",
    "#### One vs all \n",
    "* We train a linear classifier for each of the possible $k$ labels. Each classifier outputs a $1$ if it is predicted to be that label or $-1$ if not\n",
    "    * Thus, we just train $k$ of the classifiers as before, being careful to modify $y$ for each to have the values of $-1$ or $1$\n",
    "    * Each classifier will give a weight vector $w$, we store these all in the rows of a matrix $W$\n",
    "    ![](figs/weightMatrix.png)\n",
    "    * Predict by taking the largest value in $w_c^Tx_i$, and predicting the $y_i$ that the $w_c$ came from \n",
    "* PROBLEM: This may work okay, but the relative values $w_c^Tx_i$ don't have a meaning (trained $w_c$'s independently), it isn't really correct to say the largest one is most probable, each one is just trying to get the sign correct\n",
    "\n",
    "> Note: we can actually use one vs all as a multi-label classifier too by keeping the individual predictions for each possible label!\n",
    "\n",
    "\n",
    "#### Multi-class Logistic Regression (softmax)\n",
    "* This solves the problem of the relative weights being meaningless by training all $w_c$ (i.e finding $W$) at the same time\n",
    "* Loss function: \n",
    "    $$ f(W) = \\sum_{i=1}^n (-w_{y_i}^Tx_i + \\log(\\sum_{c=1}^k \\exp(w_c^Tx_i))) + \\frac{\\lambda}{2} \\sum_{j=1}^d \\sum_{c=1}^k w_{jc}^2$$\n",
    "    * This comes from the softmax function, the idea is that we want $w_{y_i}^Tx_i$ to be the biggest among all other $w_c^Tx_i$\n",
    "        * Softmax function: $P(y_i = c) = \\frac{\\exp(w_c^Tx_i)}{\\sum_{c=1}^k \\exp(w_c^Tx_i)}$\n",
    "            * Softer version of the max function, same argument as log-sum-exp on pulling out the maximum value\n",
    "    * Convex and differentiable, so we can use gradient descent, must be a bit careful as this is now a matrix we are trying to find, but we can flatten it and handle as normal\n",
    "    ![](figs/softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-family",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "![](figs/nnOverview.png)\n",
    "* In the section on latent factor models, it is mentioned that they can be used to \"pre-process\" the data in a way to change to a more useful basis for supervised learning. But, this means that we have the labels already, but we are withholding them from the latent factor model. Neural networks learn both the feature (new basis), and the classifier at the same time.\n",
    "    * Each layer is like leaning a new basis\n",
    "    * Alternatively, can think of it as a model which can learn very complex functions\n",
    "* This is a big hype area, giving unprecedented performance on ML tasks\n",
    "\n",
    "\n",
    "**Notation**:\n",
    "* Regular $X$, and $y$\n",
    "* $W$ is the matrix to get to the latent features $Z$\n",
    "* $v$ is the classifier (like $w$ from linear regression)\n",
    "    * If it is a multilabel classifier, $v \\to V$\n",
    "* $h_i()$ is the activation function, which is applied to each $Z_i$, this is generally not shown in the diagram for NN, but is shown below\n",
    "    * The activation function must be non-linear, if not mathmatically we can flatten all hidden layers to 1, and a deep network becomes useless\n",
    "* Layer: this includes the transformation from one set of neurons, to the next set\n",
    "    * Hidden layers are those that are not $X$ or $y$ (i.e the stuff in between)\n",
    "* Deep NN: more than 1 hidden layer\n",
    "    * Use superscript with brackets around to indicate which layer the learned things are for\n",
    "* Biases: we can add these to each layer, and also at the end\n",
    "\n",
    "![](figs/deepNN.png)\n",
    "![](figs/nnBias.png)\n",
    "\n",
    "**Ouput**: (for a 3 hidden layer NN)\n",
    "$$y_i = v^T h(W^{(3)} h(W^{(2)} h(W^{(1)} x_i)))$$\n",
    "* We also often include a bias on the output, and a bias on each layer\n",
    "\n",
    "\n",
    "**Loss function**: \n",
    "* 1 hidden layer \n",
    "    $$f(v, W) = \\frac{1}{2} \\sum_{i=1}^n (v^T h(Wx_i)-y_i)^2$$\n",
    "* Multi layer (3 here)\n",
    "    $$f(v, W^{(1)}, W^{(2)}, W^{(3)}) = \\frac{1}{2} \\sum_{i=1}^n (v^T h(W^{(3)} h(W^{(2)} h(W^{(1)} x_i)))-y_i)^2$$\n",
    "* Use stochastic gradient to solve this optimization problem for $v, W$\n",
    "    * Highly non-convex, can be difficult to tune\n",
    "        \n",
    "  \n",
    "**Back propagation**: this is how we compute the gradient for deep neural networks (which we then do SGD on)\n",
    "* Forward prop:\n",
    "    * Compute $z_i^{(1)}$ from $x_i$\n",
    "    * Compute $z_i^{(2)}$ from $z_i^{(1)}$\n",
    "    * ...\n",
    "    * Compute $\\hat{y}$ from $z_i^{(m)}$\n",
    "* Back prop: chain rule, plus memoization (math not shown here)\n",
    "    * Compute gradient w.r.t regression weights $v$\n",
    "    * Compute gradient w.r.t $z_i^{(m)}$ and weights $W^{(m)}$\n",
    "    * Compute gradient w.r.t $z_i^{(m-1)}$ and weights $W^{(m-1)}$\n",
    "    * ...\n",
    "    * Compute gradient w.r.t $z_i^{(1)}$ and weights $W^{(1)}$\n",
    "* Cost is $O(dk + mk^2)$ with $m$ hidden layers\n",
    "* If the last layer can have multiple classes, $v \\to V$ which is a matrix\n",
    "* **Highly non-convex**, thus parameter initialization is crucial\n",
    "    * Can't initialize weights in same layer to 0 tho, otherwise we cant change them (kill the gradient)\n",
    "    * Can't make weights to large, otherwise it will take to long\n",
    "* Using stochastic gradient is very sensitive to step size, we can do things like adding momentum to keep it moving in the same direction it was previously moving on the last step\n",
    "\n",
    "\n",
    "**Activation functions**:\n",
    "* Sigmoid: $h(z) = \\frac{1}{1+\\exp(-z)}$\n",
    "    * Has a problem with vanishing gradients, which makes optimization slow\n",
    "* ReLU: $h(z) = \\max(0, z)$\n",
    "![](figs/activation.png)\n",
    "\n",
    "**Fundamental tradeoff**: still exists here, increasing the depth, increases complexity\n",
    "* Can add regularization to the loss function, and we typically used multiple types\n",
    "    * Typical L1, L2, etc.\n",
    "        * Ex of L2 (aka weight decay):\n",
    "        $$f(v, W^{(1)}, W^{(2)}, W^{(3)}) = \\frac{1}{2} \\sum_{i=1}^n (v^T h(W^{(3)} h(W^{(2)} h(W^{(1)} x_i)))-y_i)^2 + \\frac{\\lambda_4}{2} \\|v\\|^2 + \\frac{\\lambda_3}{2}\\|W^{(3)}\\|_F^2 + \\frac{\\lambda_2}{2}\\|W^{(2)}\\|_F^2 + \\frac{\\lambda_1}{2}\\|W^{(1)}\\|_F^2$$\n",
    "    * Early stopping: this is another type of regularization, where we stop the stochastic gradient descent algorithm early if the validation error starts to increase (monitor at some steps)\n",
    "    * Drop out: on each iteration, randomly set some $x_i$ and $z_i$ to 0 (often half of them) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-bernard",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNN)\n",
    "\n",
    "**Convolutions**:\n",
    "* You have a signal vector ($w$) or matrix ($X$), and a filter vector ($w$) or matrix ($W$) \n",
    "* Idea is to slide the filter over the signal, doing matrix multiplication to get the new output\n",
    "* Can implement many different operations using a convolution filter, for example:\n",
    "    * Average: $w = [1/3, 1/3, 1/3]$\n",
    "        * Making the window bigger will give a courser average\n",
    "    * Translation: $w = [1, 0, 0, 0]$\n",
    "    * Gaussian: $w_i \\propto \\exp(-\\frac{i^2}{2 \\sigma^2})$\n",
    "    * Derivative: $w = [-1, 0, 1]$\n",
    "    * Integral: $w = [1/6, 4/6, 1/6]$ (Simpson's rule)\n",
    "* In 2D, this is like sliding a matrix over another matrix\n",
    "* 1D convolution equation: \n",
    "    $$z_i = \\sum_{j=-m}^m w_jx_{i+j}$$\n",
    "    * That is, centering $w$ at $x_i$, and taking a dot product\n",
    "* 2D convolution:\n",
    "    $$z[i_1, i_2] = \\sum_{j_1=-m}^m \\sum_{j_2=-m}^m w[j_1, j_2] * x[i_1+j_1, i_2 + j_2]$$\n",
    "* 3D convolution:\n",
    "    $$z[i_1, i_2, i_3] = \\sum_{j_1=-m}^m \\sum_{j_2=-m}^m \\sum_{j_3=-m}^m w[j_1, j_2, j_3] * x[i_1+j_1, i_2 + j_2, i_3 + j_3]$$\n",
    "* Some subtitles with boundaries of $x$ , there are a few options:\n",
    "    * Pad with zeros\n",
    "    * Replicate the last value\n",
    "    * Mirror the values\n",
    "    * Just ignore them, and return a shorter output \n",
    "* 1D convolution as a matrix multiplication:\n",
    "![](figs/convAsInt.png)\n",
    "    \n",
    "\n",
    "**Convolutioal Neural Net (CNN)**:\n",
    "* Idea: \n",
    "    * learn the convolutions\n",
    "    * save a lot of computation, because $W$ is now sparse\n",
    "    * save storage space, most weights are 0, and others are shared\n",
    "    * keep some spatial information about photos (flattening loses this)\n",
    "* 1D example:\n",
    "    * We make $W$ to be the result of several convolution (here 2 are shown)\n",
    "    ![](figs/1dCNNconv.png)\n",
    "    * Similar thing with a 2D filter, we flatten the input matrix, and flatten the filter with some additional 0's to make the multiplication produce the desired result\n",
    "* 3 layer types:\n",
    "    * Fully connected layer: usual NN with unrestricted $W$\n",
    "    * Convolutional layer: restricted $W$ to the result of several convolutions\n",
    "    * Pooling layer: combine results of convolutions\n",
    "    ![](figs/maxPooling.png)\n",
    "* Stride: how much you slide the filter at each step\n",
    "* Padding: default values placed at the image boundary\n",
    "* **Output size = (input size + 2*padding - kernel size + stride)/stride**\n",
    "\n",
    "\n",
    "**Counting parameters CNN**:\n",
    "* Example 1:\n",
    "\n",
    "    ![](figs/counting1.png)\n",
    "\n",
    "* Example 2:\n",
    "\n",
    "    ![](figs/counting2.png)\n",
    "\n",
    "* Example 3:\n",
    "\n",
    "    ![](figs/counting3.png)\n",
    "    \n",
    "    \n",
    "    \n",
    "> Note: Larger filters means more parameters, means more complexity in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-morris",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "* Models which must learn something from only $X$, not given any labels!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-level",
   "metadata": {},
   "source": [
    "## Clustering \n",
    "\n",
    "The general idea is to group the data into clusters, where the objects in the cluster are \"similar\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-direction",
   "metadata": {},
   "source": [
    "### K-means \n",
    "\n",
    "**Hyperparameters**: $k$ -> number of clusters to form  \n",
    "**Model type**: Parametric (once we find center positions $W$, that is all we need to keep)    \n",
    "**Runtime**: Train: $O()$, Predict: $O()$\n",
    "\n",
    "**Idea**:  \n",
    "1. Randomly pick $k$ initial cluster centers\n",
    "2. Assign each $X_i$ to the closest cluster center (euclidean distance) -> Update $\\hat{y}$, $O(ndk)$\n",
    "    * $\\hat{y}$: vector of length $n$, storing the group labels for each example\n",
    "3. Update the cluster center means based on the new cluster assignment -> Update $W$, $O(nd)$\n",
    "    * $W$: ($k$x$d$) matrix, where each row $W_i$ stores the cluster center of group $i$\n",
    "        * i.e the cluster center of the group that $\\hat{y}_i$ is in is located at $W[\\hat{y}_i, ;] :=W_{\\hat{y_i}}$\n",
    "4. Repeat 2 and 3 until convergence (no change in cluster centers)\n",
    "\n",
    "Generally we are trying to **minimize the cost function**:\n",
    "$$ f(W_1, W_2, ..., W_k, \\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_n) = \\sum_{i=1}^n ||W_{\\hat{y_i}}-X_i||^2$$\n",
    "\n",
    "\n",
    "This shows an example clustering, note the convex sets here\n",
    "<img src=\"figs/kmeans.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Comments**:\n",
    "* Where the solution converges (it is guaranteed to converge) depends on initialization, and it may not converge to the optimal solution sometimes\n",
    "    * Thus, we perform many **random restarts** and pick the model with the lowest cost\n",
    "* Can only form convex sets (any line between two points on the set boundary staying within the set)\n",
    "* Label switching problem: the labels are arbitrary, what really matters are which is grouped together (be cautious)\n",
    "* **Big issue**: may not know what $k$ should be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-commons",
   "metadata": {},
   "source": [
    "### Density Based (DBSCAN)\n",
    "\n",
    "**Hyperparameters**: \n",
    "* $\\epsilon$: distance to decide if another point is a neighbor\n",
    "* min_neighbors: the # of neighbors a point must have to be considered dense\n",
    "\n",
    "**Model type**: Non-parametric (must store all training points)\n",
    "**Runtime**: Train: $O()$, Predict: $O()$\n",
    "\n",
    "* Terminology:\n",
    "    * Core point: a point with at least min_neighbors\n",
    "    * Boundary point: all non-core neighbors of a core point\n",
    "    * Cluster: \n",
    "        * All core points that can be reached by following a sequence of neighboring core points\n",
    "        * All boundary points of those core points\n",
    "\n",
    "**Code**:\n",
    "* For each example $X_i$:\n",
    "    * If $X_i$ is in a cluster, do nothing\n",
    "    * Else, test weather $X_i$ is a core point\n",
    "        * If $X_i$ is non-core, do nothing\n",
    "        * Else, expandCluster\n",
    "* expandCluster(core_point):\n",
    "    * Assign all $X_i$ within distance $\\epsilon$ of core_point that isn't in a cluster to this cluster\n",
    "    * For each newly assigned neighbor $X_i$ that is a core point, expandCluster\n",
    "\n",
    "**Comments**:\n",
    "* Can form non-convex sets\n",
    "* Don't need to know the number of clusters before hand\n",
    "* There is some ambiguity of boundary points which could belong in both clusters (gets assigned to whichever grabs it first)\n",
    "* Some points may not be assigned to a cluster -> **more robust to outliers**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-gasoline",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering\n",
    "\n",
    "* Sometimes cluster densities will vary, and using a fixed clustering technique will not cluster these inner clusters correctly.\n",
    "\n",
    "* Idea: instead of fixed clustering, generate a tree with differing densities considered:\n",
    "\n",
    "![](figs/hieracrchicalCluster.png)\n",
    "\n",
    "* Types:\n",
    "    * **Hierarchical DBSCAN**: fix min_neighbors, record clusters as we vary $\\epsilon$\n",
    "    * **Agglomerative**: generates a tree -> $O(n^3d)$, each step costs $O(n^2d)$ and might only cluster 1 new point\n",
    "        1. start with each point in its own cluster\n",
    "        2. Each step merges the two \"closest\" clusters\n",
    "        3. Stop with one big cluster that has all the points\n",
    "        \n",
    "![](figs/agglomerativeClustering.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-michigan",
   "metadata": {},
   "source": [
    "## Latent Factor Models\n",
    "\n",
    "* In higher dimensions, it can be hard to find a good basis. The idea behind latent factor models is to learn the bases:\n",
    "$$X \\to \\boxed{LFM} \\to Z$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-liquid",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)\n",
    "\n",
    "$$X \\approx ZW$$\n",
    "\n",
    "* PCA is latent factor model (learns the basis) which provides dimensionality reduction of $X$ to a $(n \\times k$) matrix $Z$, where $k < d$\n",
    "* Idea is to learn $Z, W$ so that $ X \\approx ZW$ (really want to find $W$)\n",
    "    * $\\underset{k \\times d}{W}$: mapping matrix which hold $k$, $d$ dimensional basis vectors for the subspace we are using to represent $X$\n",
    "        * Rows $X_c$ are called the \"principal components\", these form the best lower dimensional hyperplane approximating the space spanned by $X$\n",
    "    * $\\underset{n \\times k}{Z}$: mapped values of $X$ in the new basis represented by $W$\n",
    "    * This is saying that $Z$ is the projection of $X$ onto the space spanned by $W$\n",
    "* **PCA train**: goal is to find $W$ (we also find $Z$ as a consequence). $W$ will be stored for the prediction phase\n",
    "    1. Center $X$, and store $\\mu_j$     \n",
    "        \\begin{align*}\n",
    "            \\mu_j &= \\frac{1}{n} \\sum_{i=1}^nx_{ij} \\text{  -> Mean of the jth feature} \\\\\n",
    "            x_{ij} &\\to x_{ij} - \\mu_j\n",
    "        \\end{align*}\n",
    "        * MUST undo this at then end too $\\implies$ save $\\mu_j$ from training!\n",
    "    2. Use the loss function to find $W$, there are a few ways to do this:\n",
    "        $$f(W, Z) = \\sum_{i=1}^n \\sum_{j=1}^d (<w^j, z_i> - x_{ij})^2 = \\|ZW-X\\|^2_F$$\n",
    "        1. Singular value decomposition (SVD): standard way to do PC, and typically PCA means this\n",
    "            * This is the best way, it will make $W, Z$ unique up to a factor of $-1$, and $W$ will be orthogonal (orthonormal basis vectors)\n",
    "            * Puts the most important components of $W$ first, and least important later\n",
    "            * Takes 4 lines:\n",
    "                ```Python\n",
    "                    mu = np.mean(X, axis=0)\n",
    "                    X -= mu # Center the data\n",
    "                    U, S, Vh = np.linalg.svd(X) # Call SVD function\n",
    "                    W = Vh[:k] # take the first k components\n",
    "                ```\n",
    "        2. Alternating minimization: more general than SVD (can use for modifications to the loss)\n",
    "            1. Fix $Z$ and find $\\nabla_w f(W, Z) = Z^TZW - Z^TX \\implies W = (Z^TZ)^{-1}Z^TX$\n",
    "            2. Fix $W$ and find $\\nabla_z f(W, Z) = ZWW^T - XW^T \\implies Z = XW^T(WW^T)^{-1}$\n",
    "            3. Repeat a, and b until convergence\n",
    "        3. Stochastic gradient descent: on each iteration, pick random $i, j$ and run the following gradient descent steps (last 2 lines)\n",
    "            \\begin{align*}\n",
    "                f(W, Z) &= \\sum_{(i, j)} f(w_j, Z_i, X_{ij}) \\\\\n",
    "                f(w_j, Z_i, X_{ij}) &= (<W^j, z_i> - x_{ij})^2 \\\\\n",
    "                w_j^{t+1} &= w_j^t - \\alpha_j^t \\nabla_{w_j} f(w_j, Z_i, X_{ij}) \\\\\n",
    "                z_j^{t+1} &= z_j^t - \\alpha_j^t \\nabla_{z_j} f(w_j, Z_i, X_{ij}) \\\\\n",
    "            \\end{align*}\n",
    "            * more general than SVD (can use for modifications to the loss)\n",
    "* **PCA Predict**:\n",
    "    1. Center $\\tilde{X}$: $\\tilde{x}_{ij} \\to \\tilde{x}_{ij} - \\mu_j$\n",
    "        * $\\mu_j$: mean of the jth feature from the **training** set (stored during train)\n",
    "    2. Find $\\tilde{Z}$ using the normal equations: \n",
    "        $$\\tilde{Z} = \\tilde{X}W^T(WW^T)^{-1}$$\n",
    "        * If we stored $W^T(WW^T)^{-1}$ in training, can save some computation\n",
    "    3. Check the reconstruction error: \n",
    "        $$E_{text} = \\| \\tilde{Z}W - \\tilde{X} \\|^2_F$$\n",
    "    4. Undo the centering if we are going to use this for something else: $(\\tilde{Z}W)_{ij} \\to (\\tilde{Z}W)_{ij} - \\mu_j$\n",
    "* **Choosing $k$**: $k$ is a hyperparameter generally, but we can choose it using **variance explained**:\n",
    "$$\\text{Variance remaining } = VR = \\frac{\\|ZW-X\\|^2_F}{\\|X\\|^2_F}$$\n",
    "    * WHERE X IS CENTERED HERE!\n",
    "    * This is the reconstruction error, normalized so that it is between 0 ($k=d$) and 1 ($k=0$)\n",
    "    * Can compute for different $k$, if we want to explain 90% of variance, choose smallest $k$ where $VR < 0.1$\n",
    "* **Problems with PCA**: scaling, rotation and label switching. $W$ and $Z$ are not unique\n",
    "    * Using SVD to train we can solve all of these up to a constant factor $-1$\n",
    "    * This other training methods (alternating minimization, stochastic gradient) still have all these problems\n",
    "* **Eigenfaces**: This is an example of the use of PCA of face images. We can reduce an image of a face down to the linear combination of eigenfaces, which are learned as the principal components. \n",
    "    * PCA can have negative values in $W$ and $Z$, so when we look at the eigenfaces, there will be light and dark spots, and they can cancel out when reconstructing the full face\n",
    "        * But, the faces won't be broken into facial features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-bhutan",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization (NMF)\n",
    "\n",
    "* This is just like PCA, but it forces all values in $W$, and $Z$ to be non-negative, thus leading to spare matrices\n",
    "    * In many cases, it doesn't make sense to have negative basis\n",
    "* Since the values can't be negative, we can't have cancellation, thus this tends to pick out specific features (ex. with faces the components will be nose, ears, teeth, etc)\n",
    "* Same loss function, but we add the constraint of $W$, $Z$ have only positive entries\n",
    "    \\begin{align*}\n",
    "        f(W, Z) &= \\sum_{i=1}^n \\sum_{j=1}^d (<w^j, w_i> - x_{ij})^2, & w_{cj}, z_{ij} > 0\n",
    "    \\end{align*}\n",
    "    * **Non-convex** loss function, thus sensitive to initialization (typically use random initialization and rerun)\n",
    "* Achieve non-negativity during the training phase the same way we train PCA with gradient descent, but by using projected gradient descent (of course, can't use SVD method):\n",
    "    * Alternating minimization (with projected gradient descent)\n",
    "    * Stochastic projected gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-howard",
   "metadata": {},
   "source": [
    "### Regularized Matrix Factorization\n",
    "\n",
    "* Same as PCA, but add L1 or L2 regularization to **BOTH** $W$ and $Z$:\n",
    "    \\begin{align*}\n",
    "        f(W, Z) &= \\frac{1}{2} \\|ZW-X\\|^2_F + \\frac{\\lambda_1}{2} \\|Z\\|^2 + \\frac{\\lambda_2}{2}\\|W\\|^2, &\\text{L2 regularization}\\\\\n",
    "        f(W, Z) &= \\frac{1}{2} \\|ZW-X\\|^2_F + \\lambda_1 \\sum_{i=1}^n \\|z_i\\|_1 + \\lambda_2 \\sum_{j=1}^2 \\|w_j\\|_1, & \\text{L1 regularization: sparse matrix factorization}\n",
    "    \\end{align*}\n",
    "    * If regularization isn't on both, then we can just reweight the other, and hence the regularization does nothing (unless its L0)\n",
    "* Can't use SVD, must use another optimization method (alternating minimization or gradient/stochastic gradient descent)\n",
    "* L1 regularization will provide similar results to NMF in terms of sparsity (not non-negativity), but now we have control over how many parameters become non-negative with $\\lambda_{1, 2}$\n",
    "    * This is good and bad, because now we have 2 more hyper parameters to select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-michael",
   "metadata": {},
   "source": [
    "### Multi-dimensional Scaling (MDS)\n",
    "\n",
    "* Non-parametric method for high dimensional data visualization\n",
    "* Directly tries to optimize for $Z$, and doesn't compute $W$ at all. The idea is that is tries to preserve distance in original space, and the learned space which is occupied by $Z$\n",
    "    * A problem with PCA, is that it just projects onto a new basis, but doesn't preserve distances well. Two point very far away could map to the same point in $Z$\n",
    "    * Since $W$ is not computed, this method cannot be used to map new data into $Z$ (no way to go between $Z$ and $\\tilde{X}$, this is purely a method to visualize different manifolds from higher dimensional spaces to lower ones, but **only works for linear manifolds**.\n",
    "* Loss function:\n",
    "    \\begin{align*}\n",
    "        f(Z) &= \\sum_{i=1}^n \\sum_{j=i+1}^n (\\|z_i - z_j\\| - \\|x_i - x_j\\|)^2, &\\text{this is the typical cost function used} \\\\\n",
    "        f(Z) &= \\sum_{i=1}^n \\sum_{j=i+1}^n d_3(d_2(z_i, z_j) - d_1(x_i, x_j))^2, &\\text{this is a general form (different distance fns)}\n",
    "    \\end{align*}\n",
    "* Optimize with gradient descent on loss function\n",
    "    * Non-convex loss, thus sensitive to initialization, and should random restart\n",
    "* **Sammon's mapping**: tried to fix a problem with the default MDS focusing on preserving large distances, but leading to crowding for smaller ones. Does so by just adding normalization\n",
    "    $$f(Z) = \\sum_{i=1}^n \\sum_{j=1}^n \\left(\\frac{d_2(z_i, z_j) - d_1(x_i, x_j)}{d_1(x_i, x_j)} \\right)^2$$\n",
    "    \n",
    "![](figs/pcaVmdsVsam.png)\n",
    "> Note: this is still unsupervised learning, colors are just there to track where things that are close in $X$ space, went in the lower dimensional space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-quest",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ISOMAP\n",
    "\n",
    "* Introduced to solve the crowding effect of MDS by focusing on geodesic distance\n",
    "* Latent factor model for visualizing data on a manifold, and works for non-linear manifolds (unlike traditional MDS)\n",
    "* Idea: use MDS, but use geodesic distance instead of euclidean\n",
    "    * Geodesic distance: distance by traversing neighboring points\n",
    "![](figs/geodesic.png)\n",
    "* Finding geodesic distance: Djekstra's shortest path algorithm\n",
    "    * Edge weights are distance between points\n",
    "* **Steps**:\n",
    "    1. Construct the graph by finding neighbors of each point:\n",
    "        * KNN neighbors, or epsilon distance (like density based clustering)\n",
    "    2. Compute edge weights: usually euclidean distance between neighbors\n",
    "    3. Computed weighted shortest path with shortest path algorithm like Dijkstra's\n",
    "        * Store these in a matrix D\n",
    "    4. Run MDS using these distances\n",
    "* This is able to extract human readable dimensions from very high dimensional images of letters rotating and scaling, or different hand positions\n",
    "    * Would need a human to actually determine what the basis represent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-radio",
   "metadata": {},
   "source": [
    "### t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "* Again, introduced to solve MSD crowding effect by focusing on preserving neighbor distances \n",
    "* Like ISOMAP (i.e also a MDS based model), but generally performs better, and is more modern\n",
    "* Not covered in much detail\n",
    "* **Summary of visualizations**:\n",
    "![](figs/visualizationSummary.png)\n",
    "    * We have the labels, but they were not given to the models for this comparrison (this is unsupervised learning)\n",
    "    * PCA is worse than all of these (not shown)\n",
    "    * This is quite amazing, t-SNE almost solves MNIST digits (a supervised learning problem) in an unsupervised way. We could then pass this transformed dataset into any supervised learning model and expect it to perform VERY well.\n",
    "    * **These visualization methods can also be used to \"preprocess\" a data set in supervised learning**\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-sellers",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
