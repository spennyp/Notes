{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intellectual-action",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#General\" data-toc-modified-id=\"General-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>General</a></span><ul class=\"toc-item\"><li><span><a href=\"#Definitions\" data-toc-modified-id=\"Definitions-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Definitions</a></span></li><li><span><a href=\"#Notation\" data-toc-modified-id=\"Notation-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Notation</a></span></li><li><span><a href=\"#Splitting-the-Data-Set\" data-toc-modified-id=\"Splitting-the-Data-Set-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Splitting the Data Set</a></span><ul class=\"toc-item\"><li><span><a href=\"#K-fold-Cross-Validation\" data-toc-modified-id=\"K-fold-Cross-Validation-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>K-fold Cross Validation</a></span></li></ul></li><li><span><a href=\"#Errors\" data-toc-modified-id=\"Errors-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Errors</a></span></li><li><span><a href=\"#Outlier-Detection\" data-toc-modified-id=\"Outlier-Detection-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Outlier Detection</a></span></li></ul></li><li><span><a href=\"#Optimization\" data-toc-modified-id=\"Optimization-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Optimization</a></span></li><li><span><a href=\"#Supervised-Learning\" data-toc-modified-id=\"Supervised-Learning-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Supervised Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#KNN\" data-toc-modified-id=\"KNN-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>KNN</a></span></li><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Naive Bayes</a></span></li><li><span><a href=\"#Ensemble-Methods\" data-toc-modified-id=\"Ensemble-Methods-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Ensemble Methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Averaging\" data-toc-modified-id=\"Averaging-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Averaging</a></span></li><li><span><a href=\"#Stacking\" data-toc-modified-id=\"Stacking-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Stacking</a></span></li><li><span><a href=\"#Random-Forests\" data-toc-modified-id=\"Random-Forests-3.4.3\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>Random Forests</a></span></li></ul></li><li><span><a href=\"#Regression\" data-toc-modified-id=\"Regression-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Change-of-basis\" data-toc-modified-id=\"Change-of-basis-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Change of basis</a></span><ul class=\"toc-item\"><li><span><a href=\"#y-intercept\" data-toc-modified-id=\"y-intercept-3.5.1.1\"><span class=\"toc-item-num\">3.5.1.1&nbsp;&nbsp;</span>y-intercept</a></span></li><li><span><a href=\"#Degree-p-polynomial\" data-toc-modified-id=\"Degree-p-polynomial-3.5.1.2\"><span class=\"toc-item-num\">3.5.1.2&nbsp;&nbsp;</span>Degree p polynomial</a></span></li><li><span><a href=\"#Periodic-bases\" data-toc-modified-id=\"Periodic-bases-3.5.1.3\"><span class=\"toc-item-num\">3.5.1.3&nbsp;&nbsp;</span>Periodic bases</a></span></li><li><span><a href=\"#Gaussian-radial-basis-function-(RBF)\" data-toc-modified-id=\"Gaussian-radial-basis-function-(RBF)-3.5.1.4\"><span class=\"toc-item-num\">3.5.1.4&nbsp;&nbsp;</span>Gaussian radial basis function (RBF)</a></span></li></ul></li><li><span><a href=\"#Loss-Functions\" data-toc-modified-id=\"Loss-Functions-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Loss Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#L2-Loss-Function-(least-squares)\" data-toc-modified-id=\"L2-Loss-Function-(least-squares)-3.5.2.1\"><span class=\"toc-item-num\">3.5.2.1&nbsp;&nbsp;</span>L2 Loss Function (least squares)</a></span></li><li><span><a href=\"#L1-Loss-Function-(robust-regression)\" data-toc-modified-id=\"L1-Loss-Function-(robust-regression)-3.5.2.2\"><span class=\"toc-item-num\">3.5.2.2&nbsp;&nbsp;</span>L1 Loss Function (robust regression)</a></span></li><li><span><a href=\"#L$\\infty$-Loss-Function-(another-robust-regression)\" data-toc-modified-id=\"L$\\infty$-Loss-Function-(another-robust-regression)-3.5.2.3\"><span class=\"toc-item-num\">3.5.2.3&nbsp;&nbsp;</span>L$\\infty$ Loss Function (another robust regression)</a></span></li></ul></li><li><span><a href=\"#Optimization-Method:-Finding-Loss-Function-Minimizer-(regression-weights)\" data-toc-modified-id=\"Optimization-Method:-Finding-Loss-Function-Minimizer-(regression-weights)-3.5.3\"><span class=\"toc-item-num\">3.5.3&nbsp;&nbsp;</span>Optimization Method: Finding Loss Function Minimizer (regression weights)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normal-Equations\" data-toc-modified-id=\"Normal-Equations-3.5.3.1\"><span class=\"toc-item-num\">3.5.3.1&nbsp;&nbsp;</span>Normal Equations</a></span></li><li><span><a href=\"#Gradient-Descent\" data-toc-modified-id=\"Gradient-Descent-3.5.3.2\"><span class=\"toc-item-num\">3.5.3.2&nbsp;&nbsp;</span>Gradient Descent</a></span></li></ul></li><li><span><a href=\"#Regularization\" data-toc-modified-id=\"Regularization-3.5.4\"><span class=\"toc-item-num\">3.5.4&nbsp;&nbsp;</span>Regularization</a></span></li></ul></li></ul></li><li><span><a href=\"#Unsupervised-Learning\" data-toc-modified-id=\"Unsupervised-Learning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Unsupervised Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#K-means\" data-toc-modified-id=\"K-means-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>K-means</a></span></li><li><span><a href=\"#Density-Based-(DBSCAN)\" data-toc-modified-id=\"Density-Based-(DBSCAN)-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Density Based (DBSCAN)</a></span></li><li><span><a href=\"#Hierarchical-Clustering\" data-toc-modified-id=\"Hierarchical-Clustering-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Hierarchical Clustering</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-defense",
   "metadata": {},
   "source": [
    "# General "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-commerce",
   "metadata": {},
   "source": [
    "Steps of ML:\n",
    "1. Identify the question / task\n",
    "2. Collect data\n",
    "3. Clean and preprocess data: remove/fix crap and noise, make categorical to numerical, feature aggregation\n",
    "4. Exploratory data analysis (EDA): looking at (visualizing) and summary statistics (mean, mode, std dev, frequencies, etc) \n",
    "5. Feature and model selection\n",
    "6. Train model\n",
    "7. Evaluate and communicate results: different error types, speed, etc.\n",
    "8. Deploy working system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-marsh",
   "metadata": {},
   "source": [
    "## Definitions \n",
    "\n",
    "* **Hyperparemeter**: these are the \"knobs\" of the model, they are the parameters that will control complexity, and are passed in by the user\n",
    "* **Model**: a structure that will have fit, and predict functions, this is where all the work happens\n",
    "    1. Training step: \n",
    "        * Input: set of $X$, with corresponding $y$ \n",
    "        * Output: a model that maps from arbitrary $X_i$ to a $y_i$\n",
    "    2. Prediction Step:\n",
    "        * Input: set of $\\tilde{X}$ and a trained model\n",
    "        * Output: predictions $\\tilde{y_i}$ \n",
    "* **Over fitting**: when a model is very complex so that $E_{train} = 0$\n",
    "* **Lazy learning**: when there is no true training phase in a model\n",
    "* **Parametric model**: when there is a **fixed** number of parameters that need to be \"learned\" (we can toss out the training data after)\n",
    "* **Non-parametric model**: when the number of parameters to be learned scales with the dataset (we may need to keep all the training data)\n",
    "* **Curse of dimensionality**: as we increase the number of dimensions (features), need exponentially more points to fill the hyper-sphere\n",
    "* **Data augmentation**: making new data from the existing by providing translations to make model more immune to noise\n",
    "* **Feature selection**: picking which features are important and getting rid of the unimportant ones\n",
    "* **Feature aggregation**: combine features to form new ones, this is useful if there are only a few examples of a particular case \n",
    "* **Feature transformation**: adjusting the data in some way like: discretization (one hot encoding), math transform (scaling or normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-washington",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "![](figs/notation.png)\n",
    "\n",
    "* $X$ is the $(n \\times d)$ *feature matrix*, where $n$ is the number of examples, and $d$ is the number of features.  \n",
    "* $y$ is the *label vector*  (only have this for supervised learning).   \n",
    "* The idea is that we use $X$ to train a model $M$, such that $M(X) = \\hat{y}$, where $\\hat{y}$ is the prediction vector (want $\\hat{y} = y$)\n",
    "\n",
    "* Breaking down the notation:\n",
    "    * $X$: feature matrix\n",
    "    * $X_i$: example $i$ ($i^{th}$ row of $X$)\n",
    "    * $X_j$: feature $j$ ($j^{th}$ column of $X$)\n",
    "    * $X_{ij}$: feature $j$ of object $i$\n",
    "    * $y$: label/output vector\n",
    "    * $y_i$: label/output of object $i$\n",
    "    * $\\hat{y}$: predicted label/output vector ($\\hat{y} = M(X)$)\n",
    "    * $\\tilde{X}$: testing feature matrix (same subscript notation as $X$)\n",
    "    * $\\tilde{y}$: testing label/output vector ($\\tilde{y} = M(\\tilde{X})$)\n",
    "\n",
    "The training error will come from the number of $\\hat{y_i} \\neq y_i$, but what is even more important is the testing error, which is the number of $\\tilde{y} \\neq y_i$ (i.e how well the model does on data that it has never seen. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-dress",
   "metadata": {},
   "source": [
    "## Splitting the Data Set\n",
    "\n",
    "* Assume we are given a independent and identically distributed (**IID**) dataset that will be used to train the model.\n",
    "    * Independent: no objects/rows depend on each other\n",
    "    * Identically distributed: from the same distribution\n",
    "    * If this is true, it means that patterns in training and testing data will be the same\n",
    "\n",
    "* From this data, we want to take some to train the model, and some to validate how well the trained model really works (i.e **split** the data). \n",
    "    * Training Data: This is a subset of the original data set that is used to train the model\n",
    "    * Validation Data: This is a subset of the original set that is used to validate that the trained model, it **can also be used for hyperparameter tuning**, but must be careful of optimization bias\n",
    "    * Test Data: This is real world data, this is what we really want our model to be good at handling\n",
    "    \n",
    "![](figs/validation.png)\n",
    "\n",
    "> Validation and testing sets and errors are sometimes used interchangeably. In many cases people wont talk about validation at all, and refer to testing only (which they really mean validation).\n",
    "\n",
    "**Golden Rule of ML**: test/validation data cannot influence the training phase in ANY way\n",
    "\n",
    "**Optimization Bias**: occurs when we minimize the validation error by using validation data to tune hyperparameters\n",
    "* To avoid: **validation data should only be used once, not over and over**, and should definitely not be used a large number of times\n",
    "* If there is optimization bias, it is a good idea to have a 2nd validation set\n",
    "\n",
    "### K-fold Cross Validation\n",
    "\n",
    "* This is a method that allows you to get more out of your data, but at the cost of more computation\n",
    "* Rather than the clean split for training and validation sets as shown above, we can:\n",
    "    1. Split the data into $K$ equal groups\n",
    "    2. Use all but 1 group to train the model, and the remaining group as the validation data\n",
    "    3. Repeat this process $K$ times, so that each of the $K$ groups is used for validation **once**\n",
    "        * Note: Only once to try to avoid optimization bias \n",
    "* **Very commonly used for hyperparameter tuning**\n",
    "    \n",
    "![](figs/kfold.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-scale",
   "metadata": {},
   "source": [
    "## Errors\n",
    "\n",
    "* 3 Types of Errors:\n",
    "    1. Training error ($E_{train}$): this is how well the model predicts on the training set (i.e on data it has seen before)\n",
    "    2. Testing error ($E_{test}$): this is how well the model predicts on the validation set (i.e on data it has not seen before)\n",
    "    3. Approximation error ($E_{approx}$): this is the difference between testing and training error\n",
    "    \n",
    "    \n",
    "**Fundamental Trade off**: only really care about the testing error, a low training error may indicate over fitting\n",
    "$$E_{approx} = E_{train} - E_{test}$$\n",
    "\n",
    "![](figs/tradeoff.png)\n",
    "\n",
    "> This is saying that, when we increase the model complexity, we will decrease $E_{train}$, but not necessarily $E_{test}$. Thus, $E_{approx}$ will increase, signifying over fitting. **What we care about is $E_{test}$**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-video",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "\n",
    "\n",
    "* We may want to remove outliers, or these may be the most interesting parts of the data. Thus it is useful to have methods to find them\n",
    "* Methods:\n",
    "    * **Model-based**: fit a probabilistic model, outliers are examples with low probability\n",
    "        * Ex: mean and std. deviation and use number of std. dev away from mean\n",
    "        * Drawbacks: these probabilistic models can be sensitive to outliers too, and make assumptions about the data\n",
    "    * **Graphical**: plot the data and a human decides if its an outlier\n",
    "        * Ex: box plot, scatter plot, etc.\n",
    "        * Drawbacks: very ambiguous\n",
    "    * **Cluster-based**: cluster the data, and find points that don't belong to clusters\n",
    "        * Ex: \n",
    "            * K-means: find points far away from any mean, or clusters with a small number of points\n",
    "            * DBSCAN: find points that don't belong to any cluster\n",
    "    * **Supervised learning**: given a dataset with labeled outliers, use supervised learning to predict if new points are outliers\n",
    "        * Drawbacks: need to generate the labeled data set of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-acceptance",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "* Optimization problem: maximizing or minimizing an **objective function**\n",
    "* Example:\n",
    "$$f(x) = (x-a)^2 + b$$\n",
    "    * Minimum: $f^\\star = \\text{min}_xf(x) = \\text{min}_x (x-a)^2 + b = b$ -> This is the minimum value of the $f$\n",
    "    * Minimizer: $x^\\star = \\text{argmin}_xf(x) = \\text{argmin}_x(x-a)^2 + b = a$ -> This is the $x$ value which gives the minimum value of $f$\n",
    "\n",
    "* **Convex function**: a function where if you draw a line between any two points, that line stays on or above the function\n",
    "    * They will not have local min or max, only global!\n",
    "    * Careful, as a straight line is considered convex, which has infinite global minimizers and maximizers \n",
    "* Constrained optimization: given a objective function, but also a constraint \n",
    "\n",
    "![](figs/minMaxNote.png)\n",
    "\n",
    "> Note: scipy.optimize.minimize takes function f, and guess x0 as parameters, and return the maximum value of f, the maximizer, and other data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-beginning",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-stuff",
   "metadata": {},
   "source": [
    "* Models that train on labeled data (the labels $y$ are the \"supervisors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-intake",
   "metadata": {},
   "source": [
    "## Decision Tree \n",
    "\n",
    "**Hyperparameters**: Max depth  \n",
    "**Model type**: Non-parametric (but a bit blurred)  \n",
    "**Runtime**: Train: $O(nd\\log(n))$, Predict: $O(\\text{tree depth})$\n",
    "\n",
    "> Note: Looking at classification decision tree only (class labels), there also exists regression trees but are not covered here\n",
    "\n",
    "* Greedy (local optimal decision), recursively defined model of decision stumps for categorical labels (i.e classification)\n",
    "* Idea: \n",
    "    * Decision stump input is a dataset, and the stump splits that into two parts based on a feature threshold value (need to find the best feature and threshold to split on in training)\n",
    "    * Feed the two output datasets into another stump\n",
    "    * Leaf stumps will have the classification\n",
    "    \n",
    "<img src=\"figs/simpleTree.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "**Stump Algorithm**:\n",
    "* For each feature: -> O(d)\n",
    "    * Sort features -> O(nlgn)\n",
    "    * For each threshold (i.e, each value in the features set): -> O(n)\n",
    "        * Generate outputs from rule -> O(1): We store the previous counts, and shift 1 sorted object and update\n",
    "        * Compute score function and update best if that is better than previous best -> O(1)\n",
    "* Pick the rule that had the best score\n",
    "\n",
    "\n",
    "**Tree Algorithm**: \n",
    "* Feed the output of one stump into a new stump and train it on that subset of data\n",
    "* Stop splitting once the max depth is reached, or it gives no better score than we had before\n",
    "\n",
    "\n",
    "**Score functions**:\n",
    "* Accuracy: use the prediction accuracy as the score (this is the naive approach)\n",
    "$$ \\text{accuracy} = \\text{count}(y_i \\neq \\hat{y}_i) $$\n",
    "    * There may be no possible split to increase accuracy, although it may decrease entropy (randomness)\n",
    "* Information gain: much better approach\n",
    "\\begin{align*}\n",
    "    \\text{Info gain} &= \\text{entropy}(y) - \\frac{n_{sat}}{n} \\text{entropy}(y_{yes}) - \\frac{n_{not}}{n} \\text{entropy}(y_{not}) \\\\\n",
    "    \\text{entropy}(y) &= -\\sum_{i=1}^n P(y_i) \\log P(y_i)\n",
    "\\end{align*}\n",
    "\n",
    "![](figs/entropy.png)\n",
    "In this image above, using accuracy score would not split this set, but using information gain will and reduce the error after completion\n",
    "\n",
    "A decision tree splits the input space into sections, where within that section a specific output will be selected. Notice that splits are straight lines.\n",
    "![](figs/decisionTreeOutputSpace.png)\n",
    "\n",
    "**Comments**:\n",
    "* Decision trees will product 0 test error by crazy over fitting so long as there are no duplicates with different labels\n",
    "    * Deeper depth is a more complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-breed",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "**Hyperparameters**: k -> the number of nearest neighbors to consider  \n",
    "**Model type**: Non-parametric (must keep entire training set)   \n",
    "**Runtime**: Train: $O(1)$ (lazy learning), Predict: $O(nd)$ (for each object in the training set, must compute euclidean distance)\n",
    "\n",
    "\n",
    "* Idea: given an input object (vector), find the $k$ nearest distance points from the training set to that object. Take the label for this object to be the most mode of those neighbors\n",
    "* Distance function: typically euclidean distance / L2 norm\n",
    "\n",
    "Knn will split the output space in more interesting ways that decision trees.\n",
    "![](figs/knnOutputSpace.png)\n",
    "\n",
    "**Comments**:\n",
    "* Run into problems if features have very different scales\n",
    "* $k=1$ will have no test error (unless duplicates with different labels)\n",
    "* Can think of $k$ like a slider on how much we trust out data. Low $k$ means we really trust it, high $k$ means we don't trust it at all\n",
    "    * Smaller $k$ is a more complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-bacteria",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "**Hyperparameters**: $\\beta$ -> Laplace smoothing parameter   \n",
    "**Model type**: Parametric (but again, it is a bit fuzzy because the number of parameters we need to store does depend on the data, but doesn't scale with more data)  \n",
    "**Runtime**: Train: $O(nd)$ (one pass over the data to count), Predict: $O(dk)$ (for each example)\n",
    "\n",
    "A probabilistic classifier with a few tricks to simplify computation\n",
    "\n",
    "**Derivation**:\n",
    "* Start with Bayes Rule: $P(y_k | x_i) = \\frac{P(x_i | y_k)P(y_k)}{P(x_i)}$, where $P(y_k) = \\frac{\\text{# of times } y_k \\text{ appears in} y}{n}$ \n",
    "    * That is, given $x_i$ give the probability of the classification $y_k$\n",
    "    * Idea is to compute this for each possible classification, and take the highest probability one as the classifier\n",
    "* Drop the $P(x_i)$ from the denominator: we only are about which has the highest probability, they will all have the same denominator, so lets not bother trying to compute it\n",
    "* Naive part: assume $P(x_i|y_k) = \\prod_{j=1}^d P(X_{ij} | y_k)$, and we know that $P(X_{ij} | y_k) = \\frac{\\text{# of times } X_{ij} \\text{ occurs with label } y_k}{\\text{number of labels of } y_k \\text{ in } y}$\n",
    "    * I.e we assume conditional independence, which is likely not true, but this is less strong of an assumption than complete independence\n",
    "* Introduce Laplace Smoothing:\n",
    "    * Problem: if the # of $X_{ij}$ occurrence with label $y_k$ is $0$, this kills the sum\n",
    "    * Solution: $P(X_{ij} | y_k) = \\frac{\\text{# of times } X_{ij} \\text{ occurs with label } y_k + \\beta}{\\text{number of labels of } y_k \\text{ in } y + c \\beta}$\n",
    "        * $\\beta$: Laplace smoothing parameter (typically 1)\n",
    "        * $c$: # of possible values $X_{ij}$ can take on (typically 2)\n",
    "        \n",
    "**Algorithm**:\n",
    "* Train:\n",
    "    * Compute and store $P(y_k)$, $P(X_{ij} | y_k)$\n",
    "    \n",
    "* Predict:\n",
    "    * For each possible label $y_k$, compute the following, and predict the label with the highest probability\n",
    "\\begin{align*}\n",
    "P(y_k | x_i) &= P(y_k) \\prod_{j=1}^d P(X_{ij} | y_k) \\\\\n",
    "P(X_{ij} | y_k) &= \\frac{\\text{# of times } X_{ij} \\text{ occurs with label } y_k + \\beta}{\\text{number of labels of } y_k \\text{ in } y + c \\beta}\n",
    "\\end{align*}\n",
    "        \n",
    "**Comments**:\n",
    "* $\\beta$ is like you have seen $\\beta$ of everything before\n",
    "    * It is like a slider on how much you trust the data (high $\\beta$ being less trust)\n",
    "        * Smaller $\\beta$ is a more complex model\n",
    "* Can use decision theory to add a cost to each output, to bias the model to pick some thing over others\n",
    "    * Ex: it is much worse to falsely predict a spam email than to miss one, so the cost of predicting spam would be high\n",
    "* With new labeled data, we can just update the counts (it is easy to add to, unlike many other ML models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-bathroom",
   "metadata": {},
   "source": [
    "\n",
    "## Ensemble Methods\n",
    "\n",
    "* Classifiers that have classifiers (KNN, decision tree, Bayes, etc) as inputs. AKA meta-learning\n",
    "* Often have higher accuracy than the input classifiers\n",
    "* Goal: significantly improve $E_{test}$ or $E_{approx}$ without doing much worse on the other one\n",
    "    * Like \"hacking\" the fundamental trade off\n",
    "\n",
    "\n",
    "### Averaging\n",
    "\n",
    "* Make the output the average of the outputs from the other models\n",
    "* Often performs better than individual models (i.e multiple ok models can make a great model)\n",
    "* Works because many classifiers will overfit, but do so independently, this reduces the overfitting and gets closer to the true prediction\n",
    "\n",
    "### Stacking\n",
    "\n",
    "* Create a new data set which is the output of different models given the same initial training set\n",
    "* Use that data set, and the true label as the inputs to another model (ex. decision tree) for generating the predicted label\n",
    "![](figs/stacking.png)\n",
    "\n",
    "\n",
    "### Random Forests\n",
    "\n",
    "**Hyperparameters**: \n",
    "* Number of features to sample for random tree stumps\n",
    "* Random tree max depth\n",
    "\n",
    "* This is one of the best ML algorithms that just works out of the box!\n",
    "* Average a set of deep **random decision trees** which we **bootstrap** \n",
    "    * Idea is that this will create trees which make independent errors, and the average will be more optimal than even the best decision tree we could train\n",
    "\n",
    "**Bootstrapping**: pick a set of $n$ object from the initial dataset chosen independently with replacement \n",
    "* Can have duplicates\n",
    "* This gives us different datasets for each one of the trees we are going to average with\n",
    "* This is from statistics\n",
    "\n",
    "**Bagging**: using bootstrap samples for ensemble learning\n",
    "\n",
    "**Random decision tree**: for each stump split, randomly sample a small number (a subset) of the features and only consider those when searching for optimal split\n",
    "* This will produce a less than optimal tree\n",
    "\n",
    "\n",
    "Random forests can product crazy looking output spaces which a regular decision tree could not make\n",
    "![](figs/randomForest.png)\n",
    "\n",
    "\n",
    "> There are many more ensembles methods which aren't covered here, like boosting, cascading, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-netscape",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "* Unlike classification, regressions methods will return a numerical value in $y$ rather than a classifier (i.e $y_i$ is no longer discrete)\n",
    "* Idea is to train a **linear** model to learn the weights $w$ (vector) such that:\n",
    "    $$\\hat{y}_i = w x_i = w_1x_{i1} + w_2 x_{i2} + ... + w_d x_{id}$$\n",
    "![](figs/1dreg.png)\n",
    "* To learn the weights, we need to **find the minimizer $w$ of the loss function $f(w)$ for our model** \n",
    "* **3 steps to specifying regression**\n",
    "    1. Choose the model (the basis function)\n",
    "    2. Choose the loss function\n",
    "    3. Choose the optimization method\n",
    "* There is an issue of uniqueness here, if $X$ is collinear, or in the simpler case of duplicate feature columns this means that the weight of one feature can be increased, while the other is decreased without changing the prediction \n",
    "    * I.e: the solution is not unique\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-clinic",
   "metadata": {},
   "source": [
    "### Change of basis\n",
    "* Idea: modify $X$ to provide different, nonlinear basis which can give us more complex (nonlinear) fits! The beauty here is **once we specify this basis function, everything else works**. We now have:\n",
    "\\begin{align*}\n",
    "    X &\\to Z \\\\\n",
    "    w &\\to v, \\text{where v is the (kx1) weight vector} \\\\\n",
    "    \\hat{y}_i &= v z_i = v_1 z_{i1} + v_2 z_{i2} + ... + v_k z_{ik}\n",
    "\\end{align*}\n",
    "\n",
    "* **Important Comments**:\n",
    "    * Can combine different basis to create very complex functions (and models)\n",
    "    * ANYTHING WE DO TO X to form Z, WE MUST DO TO THE TEST DATA ALSO\n",
    "        * i.e $X \\to Z \\implies \\tilde{X} \\to \\tilde{Z}$\n",
    "\n",
    "#### y-intercept\n",
    "* Can add y-intercept by adding a column of 1's to $X$ to form a new set $Z$\n",
    "    ![](figs/yintercept.png)\n",
    "    \n",
    "    \n",
    "#### Degree p polynomial\n",
    "* Can have a polynomial fit by taking powers of columns in $X$ to form $Z$\n",
    "    ![](figs/degreep.png)\n",
    "    > Note: this image shows $d=1$, for higher $d$ you would also have cross terms (i.e $x_{i1}^2, x_{i2}^2, x_{i1}x_{i2})$\n",
    "    ![](figs/changeOfBasis.png)\n",
    "    \n",
    "#### Periodic bases\n",
    "* Instead of polynomials we could use a periodic basis like sin or cos\n",
    "\n",
    "#### Gaussian radial basis function (RBF)\n",
    "* Here we use $n$ Gaussian bumps as the basis, with hyperparameter $\\sigma$ controlling width (smaller width means more complex model), centered at each training example \n",
    "![](figs/rbf.png)\n",
    "$$g(\\epsilon) = \\exp(- \\frac{\\epsilon^2}{2 \\theta^2})$$\n",
    "    * this is a **nonparametric model**, must store the entire dataset\n",
    "    * could also add a bias (y-intercept) and a linear basis to this\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-sixth",
   "metadata": {},
   "source": [
    "### Loss Functions\n",
    "\n",
    "* The loss function is the thing we try to optimize to find the regression weights $w$ ($v$ if change of basis). \n",
    "* The loss function will give us a cost for each set of the weights $w$, we can visualize this in parameter and data space\n",
    "    * Each point in parameter space gives us a new model, which is the orange line in data space\n",
    "    * Contours in parameter space are the values of the loss\n",
    "    * With a convex function, there is a global minimum which we are trying to find (the red star), as we move our model parameters (blue star) towards the red star we are minimizing the loss function and have a \"good\" fit (based on the particular loss function)\n",
    "![](figs/parameterDataSpace.png)\n",
    "\n",
    "\n",
    "#### L2 Loss Function (least squares)\n",
    "$$f(w) = \\frac{1}{2}||Xw-y||_2^2 = \\sum_{i=1}^n (wz_i - y_i)^2$$\n",
    "* This is non-robust regression (very sensitive to outliers)\n",
    "* Convex, differentiable, and leads to beautiful, closed form normal equations, which can be directly solved (see the section on optimization methods)\n",
    "* Leading coefficient $\\frac{1}{2}$ is just here for convenience (see the normal equations) \n",
    "    \n",
    "\n",
    "#### L1 Loss Function (robust regression)\n",
    "$$f(w) = ||Xw-y||_1 = \\sum_{i=1}^n |wz_i - y_i|$$\n",
    "* This is robust to outliers\n",
    "* Convex, but not differentiable, which causes problems for optimization methods\n",
    "* Can approximate as differentiable:\n",
    "    * **Huber Loss**: approximate this as a quadratic near the point of nondifferentiability, and use absolute value function away from that\n",
    "\\begin{align*}\n",
    "    f(w) &= \\sum_{i=1}^n h(wz_i - y_i) \\\\\n",
    "    h(z) &= \\frac{1}{2} z^2 \\text{  if  } |z| \\leq 1, \\text{  else  } |z|-\\frac{1}{2}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "#### L$\\infty$ Loss Function (another robust regression)\n",
    "$$f(w) = ||Xw-y||_{\\infty} = \\text{max}(Xw-y) \\approx \\log(\\sum_{i=1}^n \\exp(Xw-y))$$\n",
    "* Idea is to approximate the max function (convex, but not differentiable) using log-sum-exp\n",
    "    * This works because the sum of the exp will be dominated by largest, and the log will give the result\n",
    "    * Won't work that well if the values are very close to begin with\n",
    "    \n",
    "    \n",
    "    \n",
    "> A note on robustness, non-convex functions are even more robust, but very hard to optimize. The absolute value is the \"most robust\" convex loss function\n",
    "![](figs/robustness.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-cartridge",
   "metadata": {},
   "source": [
    "### Optimization Method: Finding Loss Function Minimizer (regression weights)\n",
    "\n",
    "* The idea is that we have some convex loss function (global minimum only), and we want to find the minimizer\n",
    "    * To do so, we can use the gradient, we want to find where this is 0\n",
    "* Common gradients: $c$ is a constant, $b$ is a vector, $A$ is a **symmetric** matrix\n",
    "\\begin{align*}\n",
    "    \\nabla_w(c) &= 0 \\\\\n",
    "    \\nabla_w (w^Tb) &= b\\\\\n",
    "    \\nabla_w (w^TAw) &= 2Aw\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "#### Normal Equations\n",
    "$$X^TXw=X^Ty$$  \n",
    "\n",
    "* **Runtime**: $O(nd^2 + d^3)$\n",
    "* These come from the setting the gradient of the least squares loss to 0\n",
    "\\begin{align*}\n",
    "    f(w) &= \\frac{1}{2} \\sum_{i=1}^n (w z_i - y_i)^2, \\text{note the leading 1/2, this is just for convenience} \\\\\n",
    "    &= \\frac{1}{2}||Xw-y||^2 \\\\\n",
    "    &= \\frac{1}{2}(Xw-y)^T(Xw-y) \\\\\n",
    "    &= \\frac{1}{2}(w^TAw-2w^Tb+c), \\text{A=X^TX, b=x^Ty} \\\\\n",
    "    \\nabla f(w) &= X^TXw-X^Ty, \\text{using the common gradients above} \\\\\n",
    "    \\nabla f(w) &= 0 \\implies X^TXw=X^Ty\n",
    "\\end{align*}\n",
    "\n",
    "* Note that $X^TX$ may not be invertible, thus the inverse may not exist. We must use different methods to find the solution (many libraries for this)\n",
    "* Solution may not be unique due to collinearity in $X$\n",
    "\n",
    "#### Gradient Descent\n",
    "$$w^{t+1} = w^t - \\alpha^t \\nabla f(w^t)$$\n",
    "\n",
    "* **Runtime**: $O(ndt)$  \n",
    "    * $t$: iteration number\n",
    "    * $\\alpha$: learning rate\n",
    "* Unfortunately, it is rarely the case the the loss function will have a closed form solution like with the normal equations, thus we need another method. Enter gradient descent\n",
    "\n",
    "* Idea: \n",
    "    1. Start with a random weight $w^0$\n",
    "    2. Nudge these in the direction of the $-\\nabla f(w^t)$ to find $w^{t+1}$\n",
    "    3. Repeat this until it converges (or changes less than a threshold between iterations)\n",
    "* If the function is convex, we will find a (or the) global minimum\n",
    "* Gradient descent iterations moves the blue star closer the the minimum (red star), until it converges there\n",
    "![](figs/gradientDescent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-power",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "TODO: After MT: complexity penalitys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-aurora",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "* Models which must learn something from only $X$, not given any labels!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-vocabulary",
   "metadata": {},
   "source": [
    "## Clustering \n",
    "\n",
    "The general idea is to group the data into clusters, where the objects in the cluster are \"similar\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-divorce",
   "metadata": {},
   "source": [
    "### K-means \n",
    "\n",
    "**Hyperparameters**: $k$ -> number of clusters to form  \n",
    "**Model type**: Parametric (once we find center positions $W$, that is all we need to keep)    \n",
    "**Runtime**: Train: $O()$, Predict: $O()$\n",
    "\n",
    "**Idea**:  \n",
    "1. Randomly pick $k$ initial cluster centers\n",
    "2. Assign each $X_i$ to the closest cluster center (euclidean distance) -> Update $\\hat{y}$, $O(ndk)$\n",
    "    * $\\hat{y}$: vector of length $n$, storing the group labels for each example\n",
    "3. Update the cluster center means based on the new cluster assignment -> Update $W$, $O(nd)$\n",
    "    * $W$: ($k$x$d$) matrix, where each row $W_i$ stores the cluster center of group $i$\n",
    "        * i.e the cluster center of the group that $\\hat{y}_i$ is in is located at $W[\\hat{y}_i, ;] :=W_{\\hat{y_i}}$\n",
    "4. Repeat 2 and 3 until convergence (no change in cluster centers)\n",
    "\n",
    "Generally we are trying to **minimize the cost function**:\n",
    "$$ f(W_1, W_2, ..., W_k, \\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_n) = \\sum_{i=1}^n ||W_{\\hat{y_i}}-X_i||^2$$\n",
    "\n",
    "\n",
    "This shows an example clustering, note the convex sets here\n",
    "<img src=\"figs/kmeans.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Comments**:\n",
    "* Where the solution converges (it is guaranteed to converge) depends on initialization, and it may not converge to the optimal solution sometimes\n",
    "    * Thus, we perform many **random restarts** and pick the model with the lowest cost\n",
    "* Can only form convex sets (any line between two points on the set boundary staying within the set)\n",
    "* Label switching problem: the labels are arbitrary, what really matters are which is grouped together (be cautious)\n",
    "* **Big issue**: may not know what $k$ should be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-documentation",
   "metadata": {},
   "source": [
    "### Density Based (DBSCAN)\n",
    "\n",
    "**Hyperparameters**: \n",
    "* $\\epsilon$: distance to decide if another point is a neighbor\n",
    "* min_neighbors: the # of neighbors a point must have to be considered dense\n",
    "\n",
    "**Model type**: Non-parametric (must store all training points)\n",
    "**Runtime**: Train: $O()$, Predict: $O()$\n",
    "\n",
    "* Terminology:\n",
    "    * Core point: a point with at least min_neighbors\n",
    "    * Boundary point: all non-core neighbors of a core point\n",
    "    * Cluster: \n",
    "        * All core points that can be reached by following a sequence of neighboring core points\n",
    "        * All boundary points of those core points\n",
    "\n",
    "**Code**:\n",
    "* For each example $X_i$:\n",
    "    * If $X_i$ is in a cluster, do nothing\n",
    "    * Else, test weather $X_i$ is a core point\n",
    "        * If $X_i$ is non-core, do nothing\n",
    "        * Else, expandCluster\n",
    "* expandCluster(core_point):\n",
    "    * Assign all $X_i$ within distance $\\epsilon$ of core_point that isn't in a cluster to this cluster\n",
    "    * For each newly assigned neighbor $X_i$ that is a core point, expandCluster\n",
    "\n",
    "**Comments**:\n",
    "* Can form non-convex sets\n",
    "* Don't need to know the number of clusters before hand\n",
    "* There is some ambiguity of boundary points which could belong in both clusters (gets assigned to whichever grabs it first)\n",
    "* Some points may not be assigned to a cluster -> **more robust to outliers**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-fruit",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering\n",
    "\n",
    "* Sometimes cluster densities will vary, and using a fixed clustering technique will not cluster these inner clusters correctly.\n",
    "\n",
    "* Idea: instead of fixed clustering, generate a tree with differing densities considered:\n",
    "\n",
    "![](figs/hieracrchicalCluster.png)\n",
    "\n",
    "* Types:\n",
    "    * **Hierarchical DBSCAN**: fix min_neighbors, record clusters as we vary $\\epsilon$\n",
    "    * **Agglomerative**: generates a tree -> $O(n^3d)$, each step costs $O(n^2d)$ and might only cluster 1 new point\n",
    "        1. start with each point in its own cluster\n",
    "        2. Each step merges the two \"closest\" clusters\n",
    "        3. Stop with one big cluster that has all the points\n",
    "        \n",
    "![](figs/agglomerativeClustering.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-massachusetts",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
